{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> $\\Rightarrow$ Lending Club EDA: <br> <font>\n$\\Rightarrow$ The objective here is to find the key features/indicators that will help lenders make an informed decision on lending money to a borrower.<br>\n$\\Rightarrow$ The column \"loan_status\" has three entries: *Current*, *charged Off* and *Fully Paid*. <br> $\\Rightarrow$ People may discard currently running loans and just look at *charged Off* and *Fully Paid* loans for their analysis. But we won't do that.<br> $\\Rightarrow$ Rather we will try to find some patterns in currently running loans as well. The entire analysis can be split into the following sections:","metadata":{}},{"cell_type":"markdown","source":"### <font color='cyan'> Sections in this notebook: <font>\nI. Prerequisites \n    \n    I.1. Importing modules, load data\n    I.2. Cache necessary information about the data up front\n\nII. Data understanding and cleaning\n\n    II.1. Addressing missing data\n        II.1.1. Let's get a feel for the missing data in the df first\n        II.1.2. Special cases\n    II.2. Format Conversion for certain columns\n    II.3. Quasi-Constant Variables\n        II.3.1. Numeric\n        II.3.2. For all other columns\n        II.3.3. Special Cases\n    II.4. Object type columns\n    II.5. Deriving new columns \n    II.6. Data imputation\n    II.7. Correlation\n    II.8. Outlier Detection\n        II.8.1 Box Plots\n        II.8.2. IQR Analysis\n    \nIII. Data Analysis:\n\n    III.1. Univariate Analysis\n        III.1.1. Box Plots contd.\n        III.1.2. Probability Distribution \n    III.2. Bivariate analysis\n        III.2.1. Categorical columns with a keen focus on loan_status\n            III.2.1.1. Grade\n            III.2.1.2. Home Ownership\n            III.2.1.3. Verification Status\n            III.2.1.4. Purpose\n            III.2.1.5. Employee Experience\n            III.2.1.6. Annual Income\n            III.2.1.7. Funded Amount\n            III.2.1.8. Rate of Interest\n            III.2.1.9. Public records\n            III.2.1.10. Number of inquiries in the last 6 months\n            III.2.1.11. State Address\n            III.2.1.12. Loan Term\n            III.2.1.13. Delta_bins\n        III.2.2. In between rest of the columns(minus loan_status)\n    \nIV. Conclusion\n    \nV. Recommendations","metadata":{}},{"cell_type":"markdown","source":"# <font color='goldenrod'> I. Prerequisites </font>","metadata":{}},{"cell_type":"markdown","source":"### <font color='skyblue'>  I.1. Importing modules, load data<font>","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:55:55.321063Z","iopub.execute_input":"2022-07-03T09:55:55.321723Z","iopub.status.idle":"2022-07-03T09:55:55.35758Z","shell.execute_reply.started":"2022-07-03T09:55:55.321608Z","shell.execute_reply":"2022-07-03T09:55:55.356104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:55:55.360134Z","iopub.execute_input":"2022-07-03T09:55:55.360994Z","iopub.status.idle":"2022-07-03T09:55:56.867892Z","shell.execute_reply.started":"2022-07-03T09:55:55.360944Z","shell.execute_reply":"2022-07-03T09:55:56.866854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_selection import VarianceThreshold","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:55:56.869657Z","iopub.execute_input":"2022-07-03T09:55:56.870528Z","iopub.status.idle":"2022-07-03T09:55:57.304885Z","shell.execute_reply.started":"2022-07-03T09:55:56.870476Z","shell.execute_reply":"2022-07-03T09:55:57.301945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### *1.1. Optional settings used for debugging.*","metadata":{}},{"cell_type":"code","source":"#pd.set_option('display.max_columns', 20)\n#pd.set_option('display.max_rows', 200)\n#pd.set_option('display.min_rows', 100)\n#pd.set_option('display.expand_frame_repr', True)\npd.get_option(\"display.max_rows\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:55:57.30974Z","iopub.execute_input":"2022-07-03T09:55:57.310973Z","iopub.status.idle":"2022-07-03T09:55:57.323894Z","shell.execute_reply.started":"2022-07-03T09:55:57.310914Z","shell.execute_reply":"2022-07-03T09:55:57.322434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### *1.2. Load data*","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"loan.csv\", dtype={\"next_pymnt_d\": \"string\"}) # Explicitly specificying dtype for\n                                                               # next_pymnt_d column, just to avoid pd warning","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:55:57.325819Z","iopub.execute_input":"2022-07-03T09:55:57.326261Z","iopub.status.idle":"2022-07-03T09:55:58.947121Z","shell.execute_reply.started":"2022-07-03T09:55:57.326217Z","shell.execute_reply":"2022-07-03T09:55:58.945367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color='skyblue'>  I.2. Cache necessary information about the data up front","metadata":{}},{"cell_type":"markdown","source":" <font color=\"asparagus\"> Cache the following info: \n 1. df dimension, will be used for different percentage based calculations\n 2. df itself in a separate variable","metadata":{}},{"cell_type":"code","source":"df_loan = pd.read_csv(\"loan.csv\", dtype={\"next_pymnt_d\": \"string\"})  # Caching original df, may be need it later for quick comparison","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:55:58.949115Z","iopub.execute_input":"2022-07-03T09:55:58.950027Z","iopub.status.idle":"2022-07-03T09:55:59.944211Z","shell.execute_reply.started":"2022-07-03T09:55:58.949974Z","shell.execute_reply":"2022-07-03T09:55:59.943265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nDfShape = df.shape\nnNoOfRows = nDfShape[0]\nnNoOfCols = nDfShape[1]","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:55:59.945388Z","iopub.execute_input":"2022-07-03T09:55:59.946027Z","iopub.status.idle":"2022-07-03T09:55:59.952445Z","shell.execute_reply.started":"2022-07-03T09:55:59.945991Z","shell.execute_reply":"2022-07-03T09:55:59.950802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <font color='goldenrod'> II. Data understanding and cleaning </font>","metadata":{}},{"cell_type":"markdown","source":"### <font color='skyblue'>  II.1. Addressing missing data","metadata":{}},{"cell_type":"markdown","source":"#### II.1.1.  Let's get a feel for the missing data in the df first <br>\n$\\Rightarrow$ Instead of manually tackling each column, we will try to automate as much as possible","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-07-03T09:55:59.954058Z","iopub.execute_input":"2022-07-03T09:55:59.954459Z","iopub.status.idle":"2022-07-03T09:55:59.993599Z","shell.execute_reply.started":"2022-07-03T09:55:59.954413Z","shell.execute_reply":"2022-07-03T09:55:59.992336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"$\\Rightarrow$ <font color=\"asparagus\"> The following function returns the #NaNs and #unique values in one column\"","metadata":{}},{"cell_type":"code","source":"def get_columnInfo(df, column):\n    return [df[column].isna().sum(), df[column].nunique()]","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:55:59.997632Z","iopub.execute_input":"2022-07-03T09:55:59.998821Z","iopub.status.idle":"2022-07-03T09:56:00.010657Z","shell.execute_reply.started":"2022-07-03T09:55:59.998736Z","shell.execute_reply":"2022-07-03T09:56:00.009377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"$\\Rightarrow$ <font color=\"asparagus\"> Store this information in a dictionary","metadata":{}},{"cell_type":"code","source":"columnInfo = {}\nfor col in df.columns:\n    columnInfo[col] = get_columnInfo(df,col)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:00.012097Z","iopub.execute_input":"2022-07-03T09:56:00.012792Z","iopub.status.idle":"2022-07-03T09:56:00.37898Z","shell.execute_reply.started":"2022-07-03T09:56:00.012743Z","shell.execute_reply":"2022-07-03T09:56:00.377673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"$\\Rightarrow$ <font color=\"asparagus\"> If a column has 60% missing values, we can drop it. This number can be smaller, but for this dataset 60% works","metadata":{}},{"cell_type":"code","source":"nNanThreshold = 0.6 ","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:00.381678Z","iopub.execute_input":"2022-07-03T09:56:00.382092Z","iopub.status.idle":"2022-07-03T09:56:00.38681Z","shell.execute_reply.started":"2022-07-03T09:56:00.382058Z","shell.execute_reply":"2022-07-03T09:56:00.385592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"droppedCols = []\nfor col in df.columns:\n    if (columnInfo[col][0]/nNoOfRows) >= nNanThreshold:\n        print(\"Column \", col, end=\" \")\n        print(\"missing: \", round(100*columnInfo[col][0]/nNoOfRows,2), \"%\")\n        droppedCols.append(col)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:00.388382Z","iopub.execute_input":"2022-07-03T09:56:00.388961Z","iopub.status.idle":"2022-07-03T09:56:00.407973Z","shell.execute_reply.started":"2022-07-03T09:56:00.388922Z","shell.execute_reply":"2022-07-03T09:56:00.406773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Observations and Comments*:<font> \n$\\Rightarrow$ From the stdout above, **2** columns have 64.66% and 92.99% missing, while the remaining **54** have 100% missing data.<br> (We can just use dropna() but I like this approach, we can drop things above a threshold at the same time.) <br>\n$\\Rightarrow$ I have cached this in droppedCols. Let's further analyze and drop all these columns at once at the end right before k-variate analysis","metadata":{}},{"cell_type":"markdown","source":"#### II.1.2. Special cases: id, member_id and url are not features! <br>\n#### <font color=\"asparagus\"> *Each entry will be unique, whose description from the data dictionary supplied to us is as follows:*<font>\n- member_id: A unique LC assigned Id for the borrower member.\n- id: A unique LC assigned ID for the loan listing.\n- url: URL for the LC page with listing data.<br>\n<font color=\"asparagus\"> $\\Rightarrow$ *Side note*:<font>\n    \n- Even if all of *id* was not unique and there was repetition,  keeping *url* will still not make sense, since it only contains id information. \nEg: For id: 1077501, the url is https://lendingclub.com/browse/loanDetail.action?loan_id=1077501. Really doesn't make sense to keep url.\n- Add these three columns to the list of columns to be dropped\n    ","metadata":{}},{"cell_type":"code","source":"df.id.nunique(), df.member_id.nunique(), df.url.nunique() # Proving that the values are unique : ) ","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:00.409791Z","iopub.execute_input":"2022-07-03T09:56:00.411405Z","iopub.status.idle":"2022-07-03T09:56:00.453132Z","shell.execute_reply.started":"2022-07-03T09:56:00.411252Z","shell.execute_reply":"2022-07-03T09:56:00.451847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"droppedCols.append(\"id\")\ndroppedCols.append(\"member_id\")\ndroppedCols.append(\"url\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:00.454854Z","iopub.execute_input":"2022-07-03T09:56:00.455294Z","iopub.status.idle":"2022-07-03T09:56:00.46176Z","shell.execute_reply.started":"2022-07-03T09:56:00.455258Z","shell.execute_reply":"2022-07-03T09:56:00.460531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color='skyblue'>  II.2. Format Conversion for certain columns<font>\n- term\n- int_rate\n- emp_length\n- revol_util","metadata":{}},{"cell_type":"markdown","source":"##### <font color=\"asparagus\"> $\\Rightarrow$ 1. *term*:<font>","metadata":{}},{"cell_type":"code","source":"df.term.describe(), df.term.unique()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:00.463132Z","iopub.execute_input":"2022-07-03T09:56:00.464015Z","iopub.status.idle":"2022-07-03T09:56:00.496513Z","shell.execute_reply.started":"2022-07-03T09:56:00.463978Z","shell.execute_reply":"2022-07-03T09:56:00.495446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### <font color=\"asparagus\"> $\\Rightarrow$ *Makes sense removing the string \" months\" and storing it as an int*<font>","metadata":{}},{"cell_type":"code","source":"df.term = df.term.str.replace(\" months\", \"\")\ndf.term = df.term.astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:00.498054Z","iopub.execute_input":"2022-07-03T09:56:00.498488Z","iopub.status.idle":"2022-07-03T09:56:00.564184Z","shell.execute_reply.started":"2022-07-03T09:56:00.498452Z","shell.execute_reply":"2022-07-03T09:56:00.562475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.term.unique()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:00.566566Z","iopub.execute_input":"2022-07-03T09:56:00.567115Z","iopub.status.idle":"2022-07-03T09:56:00.577298Z","shell.execute_reply.started":"2022-07-03T09:56:00.567061Z","shell.execute_reply":"2022-07-03T09:56:00.575564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### <font color=\"asparagus\"> $\\Rightarrow$ *Converting months to years* <font>","metadata":{}},{"cell_type":"code","source":"df.term = df.term//12","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:00.579098Z","iopub.execute_input":"2022-07-03T09:56:00.579799Z","iopub.status.idle":"2022-07-03T09:56:00.589181Z","shell.execute_reply.started":"2022-07-03T09:56:00.579758Z","shell.execute_reply":"2022-07-03T09:56:00.587779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.term.unique()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:00.59055Z","iopub.execute_input":"2022-07-03T09:56:00.591589Z","iopub.status.idle":"2022-07-03T09:56:00.604323Z","shell.execute_reply.started":"2022-07-03T09:56:00.591549Z","shell.execute_reply":"2022-07-03T09:56:00.602485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### <font color=\"asparagus\"> $\\Rightarrow$ 2. *int_rate*:<font> ","metadata":{}},{"cell_type":"code","source":"df.int_rate.describe()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:00.606556Z","iopub.execute_input":"2022-07-03T09:56:00.607732Z","iopub.status.idle":"2022-07-03T09:56:00.636296Z","shell.execute_reply.started":"2022-07-03T09:56:00.607688Z","shell.execute_reply":"2022-07-03T09:56:00.635028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### <font color=\"asparagus\"> $\\Rightarrow$ *We can get rid of the %* <font>","metadata":{}},{"cell_type":"code","source":"df.int_rate = df.int_rate.str.replace(\"%\",\"\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:00.637786Z","iopub.execute_input":"2022-07-03T09:56:00.63814Z","iopub.status.idle":"2022-07-03T09:56:00.676301Z","shell.execute_reply.started":"2022-07-03T09:56:00.63811Z","shell.execute_reply":"2022-07-03T09:56:00.674648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.int_rate = df.int_rate.astype(float)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:00.677973Z","iopub.execute_input":"2022-07-03T09:56:00.678931Z","iopub.status.idle":"2022-07-03T09:56:00.698666Z","shell.execute_reply.started":"2022-07-03T09:56:00.67888Z","shell.execute_reply":"2022-07-03T09:56:00.697066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### <font color=\"asparagus\"> $\\Rightarrow$ 3. *emp_length* <font>","metadata":{}},{"cell_type":"code","source":"df.emp_length.unique()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-07-03T09:56:00.700151Z","iopub.execute_input":"2022-07-03T09:56:00.700873Z","iopub.status.idle":"2022-07-03T09:56:00.714907Z","shell.execute_reply.started":"2022-07-03T09:56:00.700834Z","shell.execute_reply":"2022-07-03T09:56:00.713309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### <font color=\"asparagus\"> $\\Rightarrow$ *We can get rid of \"year\" & \"years\"* <font>","metadata":{}},{"cell_type":"code","source":"df.emp_length = df.emp_length.str.replace(\" years\",\"\")\ndf.emp_length = df.emp_length.str.replace(\" year\", \"\")\ndf.emp_length = df.emp_length.str.replace(\"+\",\"\")\ndf.emp_length = df.emp_length.str.replace(\"< \",\"\")\ndf.emp_length = df.emp_length.str.replace(\"10\",\"11\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:00.729872Z","iopub.execute_input":"2022-07-03T09:56:00.73109Z","iopub.status.idle":"2022-07-03T09:56:00.923987Z","shell.execute_reply.started":"2022-07-03T09:56:00.731042Z","shell.execute_reply":"2022-07-03T09:56:00.92305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.emp_length.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:00.925132Z","iopub.execute_input":"2022-07-03T09:56:00.926087Z","iopub.status.idle":"2022-07-03T09:56:00.941816Z","shell.execute_reply.started":"2022-07-03T09:56:00.92605Z","shell.execute_reply":"2022-07-03T09:56:00.94037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Comments*:<font> \n$\\Rightarrow$ I think it will be more meaningful to categorize this column into bins: Something like: 0-2, 2-4, 4-6, 6-8, 8-10 and >10","metadata":{}},{"cell_type":"markdown","source":"$\\Rightarrow$ But before that let's handle the null values first. I'm just gonna fill it up with the mode value, since missing values % = 1075/39717, isn't much. ","metadata":{}},{"cell_type":"code","source":"df.emp_length.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:00.9449Z","iopub.execute_input":"2022-07-03T09:56:00.945425Z","iopub.status.idle":"2022-07-03T09:56:00.962839Z","shell.execute_reply.started":"2022-07-03T09:56:00.945377Z","shell.execute_reply":"2022-07-03T09:56:00.961461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.emp_length = df.emp_length.fillna(df.emp_length.mode()[0])","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:00.964097Z","iopub.execute_input":"2022-07-03T09:56:00.965179Z","iopub.status.idle":"2022-07-03T09:56:00.986928Z","shell.execute_reply.started":"2022-07-03T09:56:00.965116Z","shell.execute_reply":"2022-07-03T09:56:00.985673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.emp_length = df.emp_length.astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:00.988273Z","iopub.execute_input":"2022-07-03T09:56:00.988993Z","iopub.status.idle":"2022-07-03T09:56:01.005762Z","shell.execute_reply.started":"2022-07-03T09:56:00.988957Z","shell.execute_reply":"2022-07-03T09:56:01.004726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emp_length_categories_list = [0, 2, 4, 6, 8, 10, 12]\nemp_length_labels_list = [\"0-2\", \"2-4\", \"4-6\", \"6-8\", \"8-10\", \"> 10\"]\ndf[\"emp_length_bins\"] = pd.cut(df.emp_length, bins=emp_length_categories_list,\n                              labels=emp_length_labels_list)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:01.007641Z","iopub.execute_input":"2022-07-03T09:56:01.008395Z","iopub.status.idle":"2022-07-03T09:56:01.021083Z","shell.execute_reply.started":"2022-07-03T09:56:01.008352Z","shell.execute_reply":"2022-07-03T09:56:01.019773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.emp_length_bins.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:01.02315Z","iopub.execute_input":"2022-07-03T09:56:01.023696Z","iopub.status.idle":"2022-07-03T09:56:01.034312Z","shell.execute_reply.started":"2022-07-03T09:56:01.023657Z","shell.execute_reply":"2022-07-03T09:56:01.033297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### <font color=\"asparagus\"> $\\Rightarrow$ 3. *revol_util* <font>","metadata":{}},{"cell_type":"code","source":"df.revol_util.describe()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:01.035591Z","iopub.execute_input":"2022-07-03T09:56:01.036078Z","iopub.status.idle":"2022-07-03T09:56:01.058674Z","shell.execute_reply.started":"2022-07-03T09:56:01.036047Z","shell.execute_reply":"2022-07-03T09:56:01.057676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.revol_util = df.revol_util.str.replace(\"%\",\"\") # Getting rid of \"%\"\ndf.revol_util= df.revol_util.astype(\"float\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:01.059772Z","iopub.execute_input":"2022-07-03T09:56:01.060473Z","iopub.status.idle":"2022-07-03T09:56:01.110724Z","shell.execute_reply.started":"2022-07-03T09:56:01.060437Z","shell.execute_reply":"2022-07-03T09:56:01.109414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color='skyblue'> II.3. Quasi-Constant Variables\n* Inspired by [Towards Data Science blog on this topic](https://towardsdatascience.com/how-to-detect-constant-quasi-constant-features-in-your-dataset-a1ab7aea34b4)\n* Check out [sklearn.feature_selection.VarianceThreshold](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html) for more info!","metadata":{}},{"cell_type":"markdown","source":"####  II.3.1. Numeric data <font>\n#### <font color=\"asparagus\"> $\\Rightarrow$ Let's drop quasi-constant features where 95% of the values are similar or constant on all the numeric columns <font>","metadata":{}},{"cell_type":"code","source":"df_numeric = df.select_dtypes(include=np.number)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:01.112177Z","iopub.execute_input":"2022-07-03T09:56:01.112785Z","iopub.status.idle":"2022-07-03T09:56:01.160268Z","shell.execute_reply.started":"2022-07-03T09:56:01.11275Z","shell.execute_reply":"2022-07-03T09:56:01.159333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_numeric.shape[1]","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:01.161701Z","iopub.execute_input":"2022-07-03T09:56:01.162288Z","iopub.status.idle":"2022-07-03T09:56:01.168703Z","shell.execute_reply.started":"2022-07-03T09:56:01.162246Z","shell.execute_reply":"2022-07-03T09:56:01.167335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sel = VarianceThreshold(threshold=0.05)\n\nsel.fit(df_numeric.iloc[:,:])\n","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:01.170723Z","iopub.execute_input":"2022-07-03T09:56:01.171108Z","iopub.status.idle":"2022-07-03T09:56:01.250776Z","shell.execute_reply.started":"2022-07-03T09:56:01.171077Z","shell.execute_reply":"2022-07-03T09:56:01.249545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Comments*:<font>\n$\\Rightarrow$ Once it is fit, the support of the vector, sel will give me all the retained features.<br>\n$\\Rightarrow$ Therefore anything that does not appear in df.columns[support()] are *quasi-constant*\n    ","metadata":{}},{"cell_type":"code","source":"quasi_constant_features_list = [x for x in df_numeric.columns if x not in df_numeric.columns[sel.get_support()]]\n","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:01.252595Z","iopub.execute_input":"2022-07-03T09:56:01.253343Z","iopub.status.idle":"2022-07-03T09:56:01.261534Z","shell.execute_reply.started":"2022-07-03T09:56:01.253308Z","shell.execute_reply":"2022-07-03T09:56:01.260183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(quasi_constant_features_list), quasi_constant_features_list","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:01.263151Z","iopub.execute_input":"2022-07-03T09:56:01.263952Z","iopub.status.idle":"2022-07-03T09:56:01.283078Z","shell.execute_reply.started":"2022-07-03T09:56:01.263914Z","shell.execute_reply":"2022-07-03T09:56:01.28127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> $\\Rightarrow$ Remember, we already have identified many columns to be dropped, so there might be an overlap. So let's check the newly identified columns","metadata":{}},{"cell_type":"code","source":"newly_identified_cols = [col for col in quasi_constant_features_list if col not in droppedCols]","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:01.285368Z","iopub.execute_input":"2022-07-03T09:56:01.286497Z","iopub.status.idle":"2022-07-03T09:56:01.293499Z","shell.execute_reply.started":"2022-07-03T09:56:01.286436Z","shell.execute_reply":"2022-07-03T09:56:01.292258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> $\\Rightarrow$ The names of the newly identified columns are:","metadata":{}},{"cell_type":"code","source":"newly_identified_cols","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:01.294953Z","iopub.execute_input":"2022-07-03T09:56:01.295712Z","iopub.status.idle":"2022-07-03T09:56:01.308345Z","shell.execute_reply.started":"2022-07-03T09:56:01.295661Z","shell.execute_reply":"2022-07-03T09:56:01.307284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> $\\Rightarrow$ If you look at the unique values of these newly identified columns, you would find that besides pub_rec_bankruptcies, the others are straight up constants and not just quasi-constant.<br><font><br>$\\Rightarrow$ But I think we should not drop pub_rec_bankruptcies altogther. This seems like an important variable to analyze against loan status(we will do this in bivariate analysis)\n#### <font color=\"asparagus\"> $\\Rightarrow$ Either way, it makes sense to drop these columns too","metadata":{}},{"cell_type":"code","source":"newly_identified_cols.pop(-2) # popping pub_rec_bankruptcies at index -2","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:01.309449Z","iopub.execute_input":"2022-07-03T09:56:01.310186Z","iopub.status.idle":"2022-07-03T09:56:01.322836Z","shell.execute_reply.started":"2022-07-03T09:56:01.31015Z","shell.execute_reply":"2022-07-03T09:56:01.321493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"newly_identified_cols","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:01.32452Z","iopub.execute_input":"2022-07-03T09:56:01.325378Z","iopub.status.idle":"2022-07-03T09:56:01.336535Z","shell.execute_reply.started":"2022-07-03T09:56:01.325327Z","shell.execute_reply":"2022-07-03T09:56:01.335441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"[df[col].nunique() for col in newly_identified_cols]\n    ","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:01.338107Z","iopub.execute_input":"2022-07-03T09:56:01.33925Z","iopub.status.idle":"2022-07-03T09:56:01.354248Z","shell.execute_reply.started":"2022-07-03T09:56:01.339188Z","shell.execute_reply":"2022-07-03T09:56:01.352924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"[droppedCols.append(col) for col in newly_identified_cols]","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:01.355783Z","iopub.execute_input":"2022-07-03T09:56:01.356153Z","iopub.status.idle":"2022-07-03T09:56:01.365638Z","shell.execute_reply.started":"2022-07-03T09:56:01.356116Z","shell.execute_reply":"2022-07-03T09:56:01.364505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### II.3.2. For all other columns","metadata":{}},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> $\\Rightarrow$ columnInfo already has the number of unique values for each column, we had cached it earlier.<font>\n#### <font color=\"asparagus\"> $\\Rightarrow$ Now is the time to add any column that has only **one** unique to the list of columns to be dropped : ) <font>","metadata":{}},{"cell_type":"code","source":"# [droppedCols.append(col) if (df[col].nunique() == 1 & col not in droppedCols) for col in columnInfo] List comprehension to do this..\nprint(\"The following columns have only 1 value throughout the data\")\nfor col in columnInfo:\n    if (df[col].nunique() == 1) & (col not in droppedCols):\n        print(f\"col: {col} \")\n        droppedCols.append(col)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:01.367048Z","iopub.execute_input":"2022-07-03T09:56:01.367957Z","iopub.status.idle":"2022-07-03T09:56:01.552627Z","shell.execute_reply.started":"2022-07-03T09:56:01.36792Z","shell.execute_reply":"2022-07-03T09:56:01.550653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### II.3.3. Special Cases\n#### <font color=\"asparagus\"> $\\Rightarrow$ It's important to note that *desc* column is pointless to have. It contains sentences and words that the borrower filled out when asking for a loan. Now we already have a column called *purpose* which as the name implies holds the purpose for which the loan was taken.<font>\n#### <font color=\"asparagus\"> $\\Rightarrow$It has 7 unique values, so we will stick with *purpose* column and drop *desc* altogether, unless we want to do sentiment analysis : )<font>","metadata":{}},{"cell_type":"code","source":"df.desc.unique() # Just an example of the contents of desc column","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:01.554547Z","iopub.execute_input":"2022-07-03T09:56:01.555087Z","iopub.status.idle":"2022-07-03T09:56:01.57327Z","shell.execute_reply.started":"2022-07-03T09:56:01.555038Z","shell.execute_reply":"2022-07-03T09:56:01.571967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"droppedCols.append(\"desc\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:01.575319Z","iopub.execute_input":"2022-07-03T09:56:01.575756Z","iopub.status.idle":"2022-07-03T09:56:01.585666Z","shell.execute_reply.started":"2022-07-03T09:56:01.575713Z","shell.execute_reply":"2022-07-03T09:56:01.584154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Comments*: <br> $\\Rightarrow$ Finally, let's drop all the columns we have accumulated so far <font>","metadata":{}},{"cell_type":"code","source":"nNoOfCols = df.shape[1]\nprint(nNoOfCols)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:01.587544Z","iopub.execute_input":"2022-07-03T09:56:01.587978Z","iopub.status.idle":"2022-07-03T09:56:01.605553Z","shell.execute_reply.started":"2022-07-03T09:56:01.587939Z","shell.execute_reply":"2022-07-03T09:56:01.604158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Number of columns to be dropped {len(set(droppedCols))}, Remainder: {nNoOfCols - len(set(droppedCols))}\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:01.60704Z","iopub.execute_input":"2022-07-03T09:56:01.607449Z","iopub.status.idle":"2022-07-03T09:56:01.618985Z","shell.execute_reply.started":"2022-07-03T09:56:01.607415Z","shell.execute_reply":"2022-07-03T09:56:01.617813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(droppedCols,axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:01.620535Z","iopub.execute_input":"2022-07-03T09:56:01.620884Z","iopub.status.idle":"2022-07-03T09:56:01.64007Z","shell.execute_reply.started":"2022-07-03T09:56:01.620852Z","shell.execute_reply":"2022-07-03T09:56:01.639121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nNoOfCols = df.shape[1] # Updating nNoOfCols","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:01.64152Z","iopub.execute_input":"2022-07-03T09:56:01.641867Z","iopub.status.idle":"2022-07-03T09:56:01.647074Z","shell.execute_reply.started":"2022-07-03T09:56:01.641837Z","shell.execute_reply":"2022-07-03T09:56:01.646114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nNoOfCols","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:01.649738Z","iopub.execute_input":"2022-07-03T09:56:01.650342Z","iopub.status.idle":"2022-07-03T09:56:01.661591Z","shell.execute_reply.started":"2022-07-03T09:56:01.650293Z","shell.execute_reply":"2022-07-03T09:56:01.660698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color='skyblue'>  II.4. Object type columns <font>","metadata":{}},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *I generally do not like to leave object type columns as is. There could be some inconsistencies in the way data is filled.*<font> \n#### <font color=\"asparagus\"> $\\Rightarrow$ Let's sanitize them and explicitly convert them to appropriate formats <font>","metadata":{}},{"cell_type":"code","source":"df_object = df.select_dtypes(include=\"object\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:01.663182Z","iopub.execute_input":"2022-07-03T09:56:01.663573Z","iopub.status.idle":"2022-07-03T09:56:01.680314Z","shell.execute_reply.started":"2022-07-03T09:56:01.663535Z","shell.execute_reply":"2022-07-03T09:56:01.678702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> Just checking what kind of values they take","metadata":{}},{"cell_type":"code","source":"for col in df_object.columns:\n    print(\"col :\", col, end=\" \")\n    print(columnInfo[col])","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:01.682129Z","iopub.execute_input":"2022-07-03T09:56:01.682567Z","iopub.status.idle":"2022-07-03T09:56:01.692747Z","shell.execute_reply.started":"2022-07-03T09:56:01.682533Z","shell.execute_reply":"2022-07-03T09:56:01.69105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> Don't want to flood stdout, just printing the unique values for columns with less than 16 unique values <font>","metadata":{}},{"cell_type":"code","source":"for col in df_object.columns:\n    if columnInfo[col][1] <= 15:\n        print(\"col :\", col, end=\" \")\n        print(df[col].unique())","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:01.695364Z","iopub.execute_input":"2022-07-03T09:56:01.695945Z","iopub.status.idle":"2022-07-03T09:56:01.729836Z","shell.execute_reply.started":"2022-07-03T09:56:01.695895Z","shell.execute_reply":"2022-07-03T09:56:01.728884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> All of these columns can first be converted to string type, since none of them have any other problems <font>","metadata":{}},{"cell_type":"code","source":"for col in df_object.columns:\n    df[col] = df[col].astype(\"string\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:01.730849Z","iopub.execute_input":"2022-07-03T09:56:01.731173Z","iopub.status.idle":"2022-07-03T09:56:01.792903Z","shell.execute_reply.started":"2022-07-03T09:56:01.731145Z","shell.execute_reply":"2022-07-03T09:56:01.791671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color='skyblue'>  II.5. Deriving new columns\n    ","metadata":{}},{"cell_type":"markdown","source":"##### <font color=\"asparagus\"> We've already converted term in months to years. Now let's look at other columns. Starting with: <font>\n##### <font color=\"asparagus\"> $\\Rightarrow$ 1. *annual_inc*:<font>\n<font color=\"asparagus\"> I think we can get a good analysis if we successfully categorize this column into bins of 20000 dollars. ","metadata":{}},{"cell_type":"code","source":"df.annual_inc.describe()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:01.794654Z","iopub.execute_input":"2022-07-03T09:56:01.795066Z","iopub.status.idle":"2022-07-03T09:56:01.815788Z","shell.execute_reply.started":"2022-07-03T09:56:01.795033Z","shell.execute_reply":"2022-07-03T09:56:01.814415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### <font color=\"asparagus\"> $\\Rightarrow$ Just checking few things about the annual_inc column <font>","metadata":{}},{"cell_type":"code","source":"np.quantile(df.annual_inc,0.99) ## 99% of the borrowers have annual inc < $234,000","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:01.817963Z","iopub.execute_input":"2022-07-03T09:56:01.819098Z","iopub.status.idle":"2022-07-03T09:56:01.826729Z","shell.execute_reply.started":"2022-07-03T09:56:01.819047Z","shell.execute_reply":"2022-07-03T09:56:01.825742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df[(df.annual_inc > np.quantile(df.annual_inc,0.99))])","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-07-03T09:56:01.828185Z","iopub.execute_input":"2022-07-03T09:56:01.828889Z","iopub.status.idle":"2022-07-03T09:56:01.846082Z","shell.execute_reply.started":"2022-07-03T09:56:01.82885Z","shell.execute_reply":"2022-07-03T09:56:01.8446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### <font color=\"asparagus\"> $\\Rightarrow$ There are still 43 borrowers(out of 398) whose income is in the top 1%, yet they defaulted. > 10%","metadata":{}},{"cell_type":"code","source":"len(df[(df.annual_inc > np.quantile(df.annual_inc,0.99)) & (df.loan_status == \"Charged Off\")])","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:01.849376Z","iopub.execute_input":"2022-07-03T09:56:01.849773Z","iopub.status.idle":"2022-07-03T09:56:01.86881Z","shell.execute_reply.started":"2022-07-03T09:56:01.849732Z","shell.execute_reply":"2022-07-03T09:56:01.867918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"annual_inc_categories_list = [0, 20000, 40000, 60000, 80000, 100000, 6000000]\nannual_inc_labels_list = [\"0-20\", \"20-40\", \"40-60\", \"60-80\", \"80-100\", \"> 100\"]\ndf[\"annual_inc_bins\"] = pd.cut(df.annual_inc, bins=annual_inc_categories_list,\n                              labels=annual_inc_labels_list)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:01.870334Z","iopub.execute_input":"2022-07-03T09:56:01.87068Z","iopub.status.idle":"2022-07-03T09:56:01.881017Z","shell.execute_reply.started":"2022-07-03T09:56:01.870648Z","shell.execute_reply":"2022-07-03T09:56:01.879609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.annual_inc_bins.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:01.883145Z","iopub.execute_input":"2022-07-03T09:56:01.88391Z","iopub.status.idle":"2022-07-03T09:56:01.901053Z","shell.execute_reply.started":"2022-07-03T09:56:01.883874Z","shell.execute_reply":"2022-07-03T09:56:01.899699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### <font color=\"asparagus\"> $\\Rightarrow$ 2. *funded_amnt*:<font>\n<font color=\"asparagus\"> I think we can get a good analysis if we successfully categorize this column as well.(bins of 5,000)","metadata":{}},{"cell_type":"code","source":"df.funded_amnt.describe()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:01.902815Z","iopub.execute_input":"2022-07-03T09:56:01.903537Z","iopub.status.idle":"2022-07-03T09:56:01.916403Z","shell.execute_reply.started":"2022-07-03T09:56:01.903489Z","shell.execute_reply":"2022-07-03T09:56:01.915413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"funded_amnt_categories_list = [0, 5000, 10000, 15000, 20000, 25000, 30000, 35000, 40000]\nfunded_amnt_labels_list = [\"0-5\", \"5-10\", \"10-15\", \"15-20\", \"20-25\", \"25-30\", \"30-35\", \"35-40\"]\ndf['funded_amnt_bins'] = pd.cut(df.funded_amnt, bins=funded_amnt_categories_list,\n                              labels=funded_amnt_labels_list)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:01.917992Z","iopub.execute_input":"2022-07-03T09:56:01.918697Z","iopub.status.idle":"2022-07-03T09:56:01.928332Z","shell.execute_reply.started":"2022-07-03T09:56:01.918653Z","shell.execute_reply":"2022-07-03T09:56:01.927386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.funded_amnt_bins.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:01.929894Z","iopub.execute_input":"2022-07-03T09:56:01.930586Z","iopub.status.idle":"2022-07-03T09:56:01.945192Z","shell.execute_reply.started":"2022-07-03T09:56:01.930541Z","shell.execute_reply":"2022-07-03T09:56:01.943649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### <font color=\"asparagus\"> $\\Rightarrow$ 3. *int_rate*:<font>\n<font color=\"asparagus\"> I think we can get a good analysis if we successfully categorize this column as well.","metadata":{}},{"cell_type":"code","source":"int_rate_range_list = [0, 8, 10, 12, 14, 16, 30]\nint_rate_labels_list = [\"0-8\", \"8-10\", \"10-12\", \"12-14\", \"14-16\", \">16\"]\ndf[\"int_rate_bins\"] = pd.cut(df[\"int_rate\"], bins=int_rate_range_list, labels=int_rate_labels_list)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:01.947394Z","iopub.execute_input":"2022-07-03T09:56:01.9483Z","iopub.status.idle":"2022-07-03T09:56:01.95903Z","shell.execute_reply.started":"2022-07-03T09:56:01.948249Z","shell.execute_reply":"2022-07-03T09:56:01.957807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"int_rate_bins\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:01.960415Z","iopub.execute_input":"2022-07-03T09:56:01.960771Z","iopub.status.idle":"2022-07-03T09:56:01.974241Z","shell.execute_reply.started":"2022-07-03T09:56:01.960742Z","shell.execute_reply":"2022-07-03T09:56:01.972733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### <font color=\"asparagus\"> $\\Rightarrow$ 4. *issue_year and last_payment_year*:<font>\n<font color=\"asparagus\"> I think if we extract the issue year and last_payment_year, we can do some sort of analysis ","metadata":{}},{"cell_type":"code","source":"mapper ={\"Jan\": 1, \"Feb\" : 2, \"Mar\": 3, \"Apr\": 4, \"May\": 5, \"Jun\": 6, \n         \"Jul\": 7, \"Aug\": 8, \"Sep\": 9, \"Oct\": 10, \"Nov\": 11, \"Dec\": 12}","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:01.975699Z","iopub.execute_input":"2022-07-03T09:56:01.976082Z","iopub.status.idle":"2022-07-03T09:56:01.986471Z","shell.execute_reply.started":"2022-07-03T09:56:01.976049Z","shell.execute_reply":"2022-07-03T09:56:01.984765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"issue_year\"] = df.issue_d.str.extract(r\"\\w+\\-(\\d+)\", expand=True)\ndf[\"issue_month\"] = df.issue_d.str.extract(r\"(\\w+)\\-\\d+\", expand=True)\ndf[\"issue_month\"] = df[\"issue_month\"].apply(lambda x: mapper[x])\ndf[\"issue_month\"] = df[\"issue_month\"].astype(float)\ndf[\"issue_year\"] = df[\"issue_year\"].astype(float)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:01.987932Z","iopub.execute_input":"2022-07-03T09:56:01.989298Z","iopub.status.idle":"2022-07-03T09:56:02.334645Z","shell.execute_reply.started":"2022-07-03T09:56:01.989235Z","shell.execute_reply":"2022-07-03T09:56:02.33305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"issue_year\"] = round(df[\"issue_year\"] + df[\"issue_month\"]/12,2)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:02.356047Z","iopub.execute_input":"2022-07-03T09:56:02.35646Z","iopub.status.idle":"2022-07-03T09:56:02.364063Z","shell.execute_reply.started":"2022-07-03T09:56:02.356427Z","shell.execute_reply":"2022-07-03T09:56:02.362952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### <font color=\"asparagus\"> $\\Rightarrow$ last_payment_year <font> \nlast_payment_year and last_payment_month first. They both have 71 missing entries","metadata":{}},{"cell_type":"code","source":"df[\"last_payment_year\"] = df.last_pymnt_d.str.extract(r\"\\w+\\-(\\d+)\", expand=True)\ndf[\"last_payment_month\"] = df.last_pymnt_d.str.extract(r\"(\\w+)\\-\\d+\", expand=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:02.36567Z","iopub.execute_input":"2022-07-03T09:56:02.36616Z","iopub.status.idle":"2022-07-03T09:56:02.659088Z","shell.execute_reply.started":"2022-07-03T09:56:02.366124Z","shell.execute_reply":"2022-07-03T09:56:02.657789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"last_payment_year\"].fillna(df.last_payment_year.mode()[0], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:02.660787Z","iopub.execute_input":"2022-07-03T09:56:02.661281Z","iopub.status.idle":"2022-07-03T09:56:02.681745Z","shell.execute_reply.started":"2022-07-03T09:56:02.661217Z","shell.execute_reply":"2022-07-03T09:56:02.680383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### <font color=\"asparagus\"> $\\Rightarrow$ Fill last_payment_month with the most common entry for the year 2013(the most common year and the one that we just filled the missing values in last_payment_year with <font> ","metadata":{}},{"cell_type":"code","source":"df[df.last_payment_year == df.last_payment_year.mode()[0]][\"last_payment_month\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:02.683781Z","iopub.execute_input":"2022-07-03T09:56:02.684886Z","iopub.status.idle":"2022-07-03T09:56:02.730054Z","shell.execute_reply.started":"2022-07-03T09:56:02.684833Z","shell.execute_reply":"2022-07-03T09:56:02.72871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"last_payment_year\"] = df.last_pymnt_d.str.extract(r\"\\w+\\-(\\d+)\", expand=True)\ndf[\"last_payment_year\"].fillna(df.last_payment_year.mode()[0], inplace=True)\ndf[\"last_payment_month\"] = df.last_pymnt_d.str.extract(r\"(\\w+)\\-\\d+\", expand=True)\ndf[\"last_payment_month\"] = df[\"last_payment_month\"].fillna(\"Mar\")\n\n\ndf[\"last_payment_month\"] =df[\"last_payment_month\"].apply(lambda x: mapper[x])\ndf[\"last_payment_month\"] = df[\"last_payment_month\"].astype(float)\ndf[\"last_payment_year\"] = df[\"last_payment_year\"].astype(float)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:02.732103Z","iopub.execute_input":"2022-07-03T09:56:02.734047Z","iopub.status.idle":"2022-07-03T09:56:02.950935Z","shell.execute_reply.started":"2022-07-03T09:56:02.734004Z","shell.execute_reply":"2022-07-03T09:56:02.949864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"last_payment_year\"] = round(df[\"last_payment_year\"] + df[\"last_payment_month\"]/12,2)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:02.952327Z","iopub.execute_input":"2022-07-03T09:56:02.952905Z","iopub.status.idle":"2022-07-03T09:56:02.962331Z","shell.execute_reply.started":"2022-07-03T09:56:02.95287Z","shell.execute_reply":"2022-07-03T09:56:02.961217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"delta\"] = round(df[\"last_payment_year\"] - df[\"issue_year\"],2)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:02.964079Z","iopub.execute_input":"2022-07-03T09:56:02.964832Z","iopub.status.idle":"2022-07-03T09:56:02.975837Z","shell.execute_reply.started":"2022-07-03T09:56:02.964779Z","shell.execute_reply":"2022-07-03T09:56:02.974841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"delta_list = [0, 1, 2, 3, 4, 5, 6, 7, 8]\ndelta_labels_list = [\"0-1\", \"1-2\", \"2-3\", \"3-4\", \"4-5\", \"5-6\", \"6-7\", \"7-8\"]\ndf[\"delta_bins\"] = pd.cut(df.delta, bins=delta_list,\n                              labels=delta_labels_list)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:02.977336Z","iopub.execute_input":"2022-07-03T09:56:02.977966Z","iopub.status.idle":"2022-07-03T09:56:02.991165Z","shell.execute_reply.started":"2022-07-03T09:56:02.977915Z","shell.execute_reply":"2022-07-03T09:56:02.989595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"delta_bins\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:02.993278Z","iopub.execute_input":"2022-07-03T09:56:02.993656Z","iopub.status.idle":"2022-07-03T09:56:03.00749Z","shell.execute_reply.started":"2022-07-03T09:56:02.993624Z","shell.execute_reply":"2022-07-03T09:56:03.006222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color='skyblue'>  II.6. Data Imputation for missing rows","metadata":{}},{"cell_type":"code","source":"df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:03.009293Z","iopub.execute_input":"2022-07-03T09:56:03.010477Z","iopub.status.idle":"2022-07-03T09:56:03.087483Z","shell.execute_reply.started":"2022-07-03T09:56:03.010429Z","shell.execute_reply":"2022-07-03T09:56:03.086592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> Low hanging fruits: <font>\n1. title \n2. revol_util\n3. last_pymnt_d\n4. last_credit_pull_d\n5. emp_length\n6. pub_rec_bankruptcies","metadata":{}},{"cell_type":"markdown","source":"##### <font color=\"asparagus\"> $\\Rightarrow$ 1. *title*<font> \n- Only 11/39717 have missing values, we can impute using value of mode ","metadata":{}},{"cell_type":"code","source":"df.title.fillna(df.title.mode()[0], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:03.088691Z","iopub.execute_input":"2022-07-03T09:56:03.089749Z","iopub.status.idle":"2022-07-03T09:56:03.114861Z","shell.execute_reply.started":"2022-07-03T09:56:03.089712Z","shell.execute_reply":"2022-07-03T09:56:03.113757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### <font color=\"asparagus\"> $\\Rightarrow$ 2. *revol_util*<font> \n- Only 50/39717 have missing values, we can impute using value of mode ","metadata":{}},{"cell_type":"code","source":"df.revol_util.fillna(df.revol_util.mode()[0], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:03.11635Z","iopub.execute_input":"2022-07-03T09:56:03.11754Z","iopub.status.idle":"2022-07-03T09:56:03.13099Z","shell.execute_reply.started":"2022-07-03T09:56:03.117488Z","shell.execute_reply":"2022-07-03T09:56:03.130029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### <font color=\"asparagus\"> $\\Rightarrow$ 3. *last_pymnt_d*<font> \n- Only 71/39717 have missing values, we can impute using value of mode ","metadata":{}},{"cell_type":"code","source":"df.last_pymnt_d.fillna(df.last_pymnt_d.mode()[0], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:03.132126Z","iopub.execute_input":"2022-07-03T09:56:03.132953Z","iopub.status.idle":"2022-07-03T09:56:03.158037Z","shell.execute_reply.started":"2022-07-03T09:56:03.132915Z","shell.execute_reply":"2022-07-03T09:56:03.156558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### <font color=\"asparagus\"> $\\Rightarrow$ 4. *last_credit_pull_d*<font> \n- Only 2/39717 have missing values, we can impute using value of mode ","metadata":{}},{"cell_type":"code","source":"df.last_credit_pull_d.fillna(df.last_credit_pull_d.mode()[0], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:03.160126Z","iopub.execute_input":"2022-07-03T09:56:03.162558Z","iopub.status.idle":"2022-07-03T09:56:03.184432Z","shell.execute_reply.started":"2022-07-03T09:56:03.162511Z","shell.execute_reply":"2022-07-03T09:56:03.183314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:03.185928Z","iopub.execute_input":"2022-07-03T09:56:03.186899Z","iopub.status.idle":"2022-07-03T09:56:03.268819Z","shell.execute_reply.started":"2022-07-03T09:56:03.186857Z","shell.execute_reply":"2022-07-03T09:56:03.267517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### <font color=\"asparagus\"> $\\Rightarrow$ 5. *emp_length* <font>\n- Though it has more missing values than the above ones we just discussed 1075/39717, isn't much. This column is categorical, plus it seems the company has more 10+ experience borrowers. We can fill with mode","metadata":{}},{"cell_type":"markdown","source":"##### <font color=\"asparagus\"> $\\Rightarrow$ 6. *pub_rec_bankruptcies* <font>","metadata":{}},{"cell_type":"code","source":"df[\"pub_rec_bankruptcies\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:03.270365Z","iopub.execute_input":"2022-07-03T09:56:03.270828Z","iopub.status.idle":"2022-07-03T09:56:03.281763Z","shell.execute_reply.started":"2022-07-03T09:56:03.270774Z","shell.execute_reply":"2022-07-03T09:56:03.280476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"pub_rec_bankruptcies\"].fillna(df[\"pub_rec_bankruptcies\"].mode()[0], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:03.285401Z","iopub.execute_input":"2022-07-03T09:56:03.286332Z","iopub.status.idle":"2022-07-03T09:56:03.294182Z","shell.execute_reply.started":"2022-07-03T09:56:03.28628Z","shell.execute_reply":"2022-07-03T09:56:03.292817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"pub_rec_bankruptcies\"].isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:03.295667Z","iopub.execute_input":"2022-07-03T09:56:03.296374Z","iopub.status.idle":"2022-07-03T09:56:03.308444Z","shell.execute_reply.started":"2022-07-03T09:56:03.296336Z","shell.execute_reply":"2022-07-03T09:56:03.30724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color='skyblue'>  II.7. Correlation<font>","metadata":{}},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Need to create a heatmap of all the retained numeric variables and check the relationship* <font>","metadata":{}},{"cell_type":"code","source":"# Define the heatmap parameters\npd.options.display.float_format = \"{:,.2f}\".format","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:03.309825Z","iopub.execute_input":"2022-07-03T09:56:03.310167Z","iopub.status.idle":"2022-07-03T09:56:03.316407Z","shell.execute_reply.started":"2022-07-03T09:56:03.310137Z","shell.execute_reply":"2022-07-03T09:56:03.315251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_numeric = df.select_dtypes(include=np.number)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:03.317714Z","iopub.execute_input":"2022-07-03T09:56:03.318126Z","iopub.status.idle":"2022-07-03T09:56:03.338928Z","shell.execute_reply.started":"2022-07-03T09:56:03.318094Z","shell.execute_reply":"2022-07-03T09:56:03.337347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_mat = df_numeric.corr()\n\n# Mask the upper part of the heatmap\nmask = np.triu(np.ones_like(corr_mat, dtype=bool))\n\n# Choose the color map\ncmap = \"viridis\"\n\ncorr_mat[(corr_mat < 0.1) & (corr_mat > -0.1)] = 0 # Easier to view, don't really care obout weak correlations\n# plot the heatmap\nplt.figure(figsize=(30,30))\nsns.heatmap(corr_mat, mask=mask, vmax=1.0, vmin=-1.0, linewidths=0.1,\n            annot_kws={\"size\": 8, \"color\": \"black\"}, square=True, cmap=cmap, annot=True)\nplt.show()\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:03.341134Z","iopub.execute_input":"2022-07-03T09:56:03.341623Z","iopub.status.idle":"2022-07-03T09:56:06.084417Z","shell.execute_reply.started":"2022-07-03T09:56:03.341587Z","shell.execute_reply":"2022-07-03T09:56:06.083614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> 1. We need to make a decision on these highly correlation variables.<font> \n#### <font color=\"asparagus\"> 2. No need to keep them all, rather, we can discard all but one and continue <font>","metadata":{}},{"cell_type":"markdown","source":"##### Strengh of relationship\n\n* |r| < 0.3 $\\Rightarrow$ None or Very Weak\n* 0.3 < |r| < 0.5 $\\Rightarrow$ Weak\n* 0.5 < |r| < 0.7 $\\Rightarrow$ Moderate\n* |r| > 0.7 $\\Rightarrow$ Strong","metadata":{}},{"cell_type":"code","source":"colsToDrop_fromCorr = [] # New list to maintain the columns we want to drop","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:06.085709Z","iopub.execute_input":"2022-07-03T09:56:06.086749Z","iopub.status.idle":"2022-07-03T09:56:06.091019Z","shell.execute_reply.started":"2022-07-03T09:56:06.086714Z","shell.execute_reply":"2022-07-03T09:56:06.090101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> $\\Rightarrow$ *Focusing on funded_amount, loan_amount, funded_amount_inv first* <font>\n1. loan_amnt: The listed amount of the loan applied for by the borrower. If at some point in time, the credit department reduces the loan amount, then it will be reflected in this value.\n2. funded_amnt: The total amount committed to that loan at that point in time.\n3. funded_amnt_inv: The total amount committed by investors for that loan at that point in time.<br>\nThe correlation factor, r, is almost 1 for these guys\n    \nIn short, a borrower approaches the company to ask for an amount, *loan_amnt*. The company agrees for a certain amount, *funded_amnt*. *funded_amnt_inv*: Sometimes, the lending club themselves step in and fund the amount. This is that. <br>\n$\\Rightarrow$ Conclusion: We can just keep *funded_amnt* and discard the rest.We could have easily done our analysis with loan_amnt and dropped funded_amnt instead and our observations wouldn't have changed, because *loan_amnt* will satisfy the condition:<br>\n    *funded_amnt* <= *loan_amnt* \n\n    ","metadata":{}},{"cell_type":"code","source":"colsToDrop_fromCorr.append(\"loan_amnt\")\ncolsToDrop_fromCorr.append(\"funded_amnt_inv\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:06.092527Z","iopub.execute_input":"2022-07-03T09:56:06.093297Z","iopub.status.idle":"2022-07-03T09:56:06.10305Z","shell.execute_reply.started":"2022-07-03T09:56:06.093158Z","shell.execute_reply":"2022-07-03T09:56:06.101947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> $\\Rightarrow$ *Commenting on installment* <font>","metadata":{}},{"cell_type":"markdown","source":"#### *installment* is the monthly payment owed by the borrower if the loan originates as per the data dictionary. <br>\n#### Again, r >0.9 with \"loan_amnt\", \"funded_amnt\", \"funded_amnt_inv\". <br>\n#### Therefore, *installment* can be dropped as well.","metadata":{}},{"cell_type":"code","source":"colsToDrop_fromCorr.append(\"installment\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:06.104441Z","iopub.execute_input":"2022-07-03T09:56:06.105292Z","iopub.status.idle":"2022-07-03T09:56:06.114769Z","shell.execute_reply.started":"2022-07-03T09:56:06.105236Z","shell.execute_reply":"2022-07-03T09:56:06.113927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> $\\Rightarrow$ *Commenting on total_xx columns* \nThis is information that is not visible at the time of loan application, because many fields like *total_pymnt* will fill up with time once loan is approved. But we will still analyze them.  <font>","metadata":{}},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> 1. total_pymnt: Payments received to date for total amount funded<font>\n#### <font color=\"asparagus\"> 2. total_pymnt_inv: Payments received to date for portion of total amount funded by investors<font>\n#### <font color=\"asparagus\"> 3. total_rec_prncp: Principal received to date<font>\n#### <font color=\"asparagus\"> 4. total_rec_int: Interest received to date<font> \n##### <font color=\"asparagus\"> $\\Rightarrow$ We cannot drop total_pymnt, but as it stands, it does not give us good information about the borrower's current status of payment(how much left, how much paid). They are just raw numbers. <br>\n##### <font color=\"asparagus\"> $\\Rightarrow$ What we can do instead is add a new column: Percentage of funded amount paid.\nIf a borrower pays the entire amount, the percentage will 100%. Formula: <br>(total_pymnt - total_rec_int - total_rec_late_fee)/funded_amnt.<br> \n#### *Side note*: These columns also show a high correlation with *\"loan_amnt\", \"funded_amnt\", \"funded_amnt_inv\"* (~0.75)<br>\n\n**Conclusion**: We can hold on to *total_pymnt* and discard remaining. By the way, *funded_amnt* is highly correlated with *total_pymnt* as well\n    ","metadata":{}},{"cell_type":"code","source":"df[\"Pct_Payment_Received\"] = round(100 * (df.total_pymnt - df.total_rec_int - df.total_rec_late_fee)/df.funded_amnt,2) ","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:06.115988Z","iopub.execute_input":"2022-07-03T09:56:06.116516Z","iopub.status.idle":"2022-07-03T09:56:06.128678Z","shell.execute_reply.started":"2022-07-03T09:56:06.116485Z","shell.execute_reply":"2022-07-03T09:56:06.12742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"colsToDrop_fromCorr.append(\"total_pymnt_inv\")\ncolsToDrop_fromCorr.append(\"total_rec_prncp\")\ncolsToDrop_fromCorr.append(\"total_rec_int\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:06.130124Z","iopub.execute_input":"2022-07-03T09:56:06.13112Z","iopub.status.idle":"2022-07-03T09:56:06.13836Z","shell.execute_reply.started":"2022-07-03T09:56:06.131079Z","shell.execute_reply":"2022-07-03T09:56:06.137052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"colsToDrop_fromCorr\n","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:06.14013Z","iopub.execute_input":"2022-07-03T09:56:06.140718Z","iopub.status.idle":"2022-07-03T09:56:06.15136Z","shell.execute_reply.started":"2022-07-03T09:56:06.140671Z","shell.execute_reply":"2022-07-03T09:56:06.14988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> $\\Rightarrow$ *Commenting on (total_acc, open_acc): r = 0.69 and (collection_recovery_fee, recoveries)*: r = 0.8 <font>","metadata":{}},{"cell_type":"markdown","source":"#### 1. total_acc: The total number of credit lines currently in the borrower's credit file\n#### 2. open_acc: The number of open credit lines in the borrower's credit file.\n\n$\\Rightarrow$ Makes sense that they are highly correlated. I think we can just **keep the number of open credit lines** and **drop the total**, because **total will include open and closed**. **We are only interested in the ones that are currently running**(this is where we can find whether the borrower is about to default or not)","metadata":{}},{"cell_type":"code","source":"colsToDrop_fromCorr.append(\"total_acc\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:06.153107Z","iopub.execute_input":"2022-07-03T09:56:06.153881Z","iopub.status.idle":"2022-07-03T09:56:06.161862Z","shell.execute_reply.started":"2022-07-03T09:56:06.153833Z","shell.execute_reply":"2022-07-03T09:56:06.160932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 1. recoveries: post charge off gross recovery\n#### 2. collection_recovery_fee: post charge off collection fee<br>\n$\\Rightarrow$ Both of these quantities are concerned with post charge off scenarios. Most of the values are 0 for both of them as well. I think it is safe to drop recoveries","metadata":{}},{"cell_type":"code","source":"colsToDrop_fromCorr.append(\"recoveries\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:06.163504Z","iopub.execute_input":"2022-07-03T09:56:06.164001Z","iopub.status.idle":"2022-07-03T09:56:06.173648Z","shell.execute_reply.started":"2022-07-03T09:56:06.163955Z","shell.execute_reply":"2022-07-03T09:56:06.172757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"colsToDrop_fromCorr","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-07-03T09:56:06.174789Z","iopub.execute_input":"2022-07-03T09:56:06.175548Z","iopub.status.idle":"2022-07-03T09:56:06.18983Z","shell.execute_reply.started":"2022-07-03T09:56:06.17551Z","shell.execute_reply":"2022-07-03T09:56:06.188601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(colsToDrop_fromCorr,axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:06.192058Z","iopub.execute_input":"2022-07-03T09:56:06.192571Z","iopub.status.idle":"2022-07-03T09:56:06.207949Z","shell.execute_reply.started":"2022-07-03T09:56:06.192525Z","shell.execute_reply":"2022-07-03T09:56:06.206952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:06.210198Z","iopub.execute_input":"2022-07-03T09:56:06.210599Z","iopub.status.idle":"2022-07-03T09:56:06.294952Z","shell.execute_reply.started":"2022-07-03T09:56:06.210568Z","shell.execute_reply":"2022-07-03T09:56:06.293832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nNoOfCols = df.shape[1]","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:06.296421Z","iopub.execute_input":"2022-07-03T09:56:06.297168Z","iopub.status.idle":"2022-07-03T09:56:06.301747Z","shell.execute_reply.started":"2022-07-03T09:56:06.297129Z","shell.execute_reply":"2022-07-03T09:56:06.300647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nNoOfCols","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:06.303152Z","iopub.execute_input":"2022-07-03T09:56:06.303519Z","iopub.status.idle":"2022-07-03T09:56:06.317712Z","shell.execute_reply.started":"2022-07-03T09:56:06.303489Z","shell.execute_reply":"2022-07-03T09:56:06.316681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color='skyblue'>  II.8. Outlier Detection<font>\n1. Box Plots<br>\n2. Mahalanobis Distance\n\nWhen describing relationship between two variables, correlations is necessary, but not sufficient. More plots will help","metadata":{}},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Sequence*:<font>\n$\\Rightarrow$ <font color=\"asparagus\"> Boxplot first then  \n$\\Rightarrow$ <font color=\"asparagus\">  I'm gonnna calculate the IQRs for every column and store the locations of every row that lies outside the 1.5IQR range","metadata":{}},{"cell_type":"markdown","source":"### <font color='skyblue'>  II.8.1 Box Plots<font>","metadata":{}},{"cell_type":"code","source":"df_numeric = df.select_dtypes(include=np.number)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:06.31943Z","iopub.execute_input":"2022-07-03T09:56:06.320049Z","iopub.status.idle":"2022-07-03T09:56:06.331147Z","shell.execute_reply.started":"2022-07-03T09:56:06.320015Z","shell.execute_reply":"2022-07-03T09:56:06.330291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#fig, axes = plt.subplots(7,2,figsize=(20,30))\nfor col in df_numeric.columns:\n    plt.figure(figsize=(10,6))\n    sns.boxplot(x=\"loan_status\", y=col,\n                data=df)\n    plt.show()\n    ","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:06.332459Z","iopub.execute_input":"2022-07-03T09:56:06.333344Z","iopub.status.idle":"2022-07-03T09:56:11.904515Z","shell.execute_reply.started":"2022-07-03T09:56:06.33331Z","shell.execute_reply":"2022-07-03T09:56:11.903294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Observations and Comments*:<font> \n$\\Rightarrow$ <font color=\"asparagus\"> Looking at the box plot, it looks like the median(and range) of percentage_payment_received is the lowest for \"Charged Off\" borrowers. This is a good indicator for borrowers who are likely to default. <br> **You will see later in Bivariate analysis how this has influence on *delta_bins* variable as well**","metadata":{}},{"cell_type":"code","source":"indicators = []\nindicators.append(\"Pct_Payment_Received\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:11.906119Z","iopub.execute_input":"2022-07-03T09:56:11.907527Z","iopub.status.idle":"2022-07-03T09:56:11.913454Z","shell.execute_reply.started":"2022-07-03T09:56:11.907475Z","shell.execute_reply":"2022-07-03T09:56:11.912559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"indicators","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:11.915604Z","iopub.execute_input":"2022-07-03T09:56:11.916501Z","iopub.status.idle":"2022-07-03T09:56:11.931725Z","shell.execute_reply.started":"2022-07-03T09:56:11.916445Z","shell.execute_reply":"2022-07-03T09:56:11.930412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in df_numeric.columns:\n    plt.figure(figsize=(10,6))\n    sns.boxplot(x=\"annual_inc_bins\", y=col,\n                data=df)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:11.933615Z","iopub.execute_input":"2022-07-03T09:56:11.934075Z","iopub.status.idle":"2022-07-03T09:56:18.253021Z","shell.execute_reply.started":"2022-07-03T09:56:11.934032Z","shell.execute_reply":"2022-07-03T09:56:18.252174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Observations and Comments*:<font> \n$\\Rightarrow$ <font color=\"asparagus\"> Borrowers with high income borrow the higest amount. They also have made more inquiries in the past 6 months as compared to others. They have a lot more open accounts than borrowers with lower income than them. <br> $\\Rightarrow$ Since they tend to borrow more, the total payment received is also more. <font><br>","metadata":{}},{"cell_type":"code","source":"for col in df_numeric.columns:\n    plt.figure(figsize=(10,6))\n    sns.boxplot(x=\"funded_amnt_bins\", y=col,\n                data=df)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:18.254059Z","iopub.execute_input":"2022-07-03T09:56:18.254892Z","iopub.status.idle":"2022-07-03T09:56:25.490178Z","shell.execute_reply.started":"2022-07-03T09:56:18.254857Z","shell.execute_reply":"2022-07-03T09:56:25.488793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Observations and Comments*:<font> \n$\\Rightarrow$ <font color=\"asparagus\"> Higher the funded amount, higher is the interest rate as well.<br>$\\Rightarrow$ When we look at the inquiries made in the last 6 months vs funded_amnt_bins, 30000-35000 categories have only one outlier. Borrowers in the range 35000-40000 have not made any inquiries.<br>$\\Rightarrow$ People that borow a high amount, tend to have more open accounts too.<font><br>","metadata":{}},{"cell_type":"code","source":"for col in df_numeric.columns:\n    plt.figure(figsize=(10,6))\n    sns.boxplot(x=\"int_rate_bins\", y=col,\n                data=df)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:25.491661Z","iopub.execute_input":"2022-07-03T09:56:25.492Z","iopub.status.idle":"2022-07-03T09:56:32.212376Z","shell.execute_reply.started":"2022-07-03T09:56:25.491971Z","shell.execute_reply":"2022-07-03T09:56:32.211492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"$\\Rightarrow$ <font color=\"asparagus\"> There are quite a few columns that seem to be heavily skewed towards one value. Eg: total_rec_late_fee, pub_rec, delinq_2yrs, annual_inc<br>\n$\\Rightarrow$ <font color=\"asparagus\"> An IQR analysis will help us get a sense of the number of outliers ","metadata":{}},{"cell_type":"markdown","source":"### <font color='skyblue'>  II.8.2. IQR Analysis<font>","metadata":{}},{"cell_type":"code","source":"column_quantile_info ={}\nfor col in df_numeric.columns:\n    Q1 = np.quantile(df[col], 0.25)\n    Q2 = np.quantile(df[col], 0.5)\n    Q3 = np.quantile(df[col], 0.75)\n    Q4 = np.quantile(df[col], 0.99)\n    Q5 = np.quantile(df[col], 0.01)\n    IQR = Q3 - Q1\n    column_quantile_info[col] = [Q1, Q2, Q3, IQR, Q3 + 1.5*IQR, Q1 - 1.5*IQR, Q4, Q5]","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:32.213814Z","iopub.execute_input":"2022-07-03T09:56:32.214591Z","iopub.status.idle":"2022-07-03T09:56:32.292038Z","shell.execute_reply.started":"2022-07-03T09:56:32.214543Z","shell.execute_reply":"2022-07-03T09:56:32.291113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"$\\Rightarrow$ <font color=\"asparagus\"> Let's just say outliers are those that are in the top 1% or bottom 1 %","metadata":{}},{"cell_type":"code","source":"upper_outlier_in_every_column = {}","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:32.293444Z","iopub.execute_input":"2022-07-03T09:56:32.294123Z","iopub.status.idle":"2022-07-03T09:56:32.299971Z","shell.execute_reply.started":"2022-07-03T09:56:32.294078Z","shell.execute_reply":"2022-07-03T09:56:32.298519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in df_numeric.columns:\n    #print((np.where(df[col] > column_quantile_info[col][6])))\n    upper_outlier_in_every_column[col] = np.where(df[col] > column_quantile_info[col][6])","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:32.301994Z","iopub.execute_input":"2022-07-03T09:56:32.302832Z","iopub.status.idle":"2022-07-03T09:56:32.320658Z","shell.execute_reply.started":"2022-07-03T09:56:32.302782Z","shell.execute_reply":"2022-07-03T09:56:32.318692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in df_numeric.columns:\n    print(len(upper_outlier_in_every_column[col][0]))","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:32.322895Z","iopub.execute_input":"2022-07-03T09:56:32.323709Z","iopub.status.idle":"2022-07-03T09:56:32.331405Z","shell.execute_reply.started":"2022-07-03T09:56:32.323662Z","shell.execute_reply":"2022-07-03T09:56:32.330091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"$\\Rightarrow$ <font color=\"asparagus\"> That's a lot of outliers in every column. Let's try to see if there are any common rows among all columns <font>","metadata":{}},{"cell_type":"code","source":"common = np.intersect1d(upper_outlier_in_every_column[\"int_rate\"], upper_outlier_in_every_column[\"last_pymnt_amnt\"])","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:32.333572Z","iopub.execute_input":"2022-07-03T09:56:32.334516Z","iopub.status.idle":"2022-07-03T09:56:32.344455Z","shell.execute_reply.started":"2022-07-03T09:56:32.33446Z","shell.execute_reply":"2022-07-03T09:56:32.343572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in df_numeric.columns:\n    if len(upper_outlier_in_every_column[col][0]) > 300:\n        common = np.intersect1d(common, upper_outlier_in_every_column[col][0])\n        print(col, \": \", common)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:32.346988Z","iopub.execute_input":"2022-07-03T09:56:32.347471Z","iopub.status.idle":"2022-07-03T09:56:32.361278Z","shell.execute_reply.started":"2022-07-03T09:56:32.347425Z","shell.execute_reply":"2022-07-03T09:56:32.360004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"common","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:32.363721Z","iopub.execute_input":"2022-07-03T09:56:32.364418Z","iopub.status.idle":"2022-07-03T09:56:32.372968Z","shell.execute_reply.started":"2022-07-03T09:56:32.364167Z","shell.execute_reply":"2022-07-03T09:56:32.371644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lower_outlier_in_every_column = {}","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:32.376077Z","iopub.execute_input":"2022-07-03T09:56:32.37682Z","iopub.status.idle":"2022-07-03T09:56:32.383328Z","shell.execute_reply.started":"2022-07-03T09:56:32.37677Z","shell.execute_reply":"2022-07-03T09:56:32.38198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in df_numeric.columns:\n    #print((np.where(df[col] > column_quantile_info[col][6])))\n    lower_outlier_in_every_column[col] = np.where(df[col] < column_quantile_info[col][7])","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:32.38544Z","iopub.execute_input":"2022-07-03T09:56:32.386323Z","iopub.status.idle":"2022-07-03T09:56:32.39992Z","shell.execute_reply.started":"2022-07-03T09:56:32.38627Z","shell.execute_reply":"2022-07-03T09:56:32.398954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in df_numeric.columns:\n    print(len(lower_outlier_in_every_column[col][0]))","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:32.401974Z","iopub.execute_input":"2022-07-03T09:56:32.403083Z","iopub.status.idle":"2022-07-03T09:56:32.411123Z","shell.execute_reply.started":"2022-07-03T09:56:32.402876Z","shell.execute_reply":"2022-07-03T09:56:32.410341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lower_common = lower_outlier_in_every_column[\"funded_amnt\"][0]","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:32.41319Z","iopub.execute_input":"2022-07-03T09:56:32.414013Z","iopub.status.idle":"2022-07-03T09:56:32.421741Z","shell.execute_reply.started":"2022-07-03T09:56:32.413969Z","shell.execute_reply":"2022-07-03T09:56:32.420255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in df_numeric.columns:\n    if len(lower_outlier_in_every_column[col][0]) > 300:\n        lower_common = np.intersect1d(lower_common, lower_outlier_in_every_column[col][0])\n        print(col, \": \", lower_common)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:32.423527Z","iopub.execute_input":"2022-07-03T09:56:32.424357Z","iopub.status.idle":"2022-07-03T09:56:32.43516Z","shell.execute_reply.started":"2022-07-03T09:56:32.42431Z","shell.execute_reply":"2022-07-03T09:56:32.434035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lower_common","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:32.437028Z","iopub.execute_input":"2022-07-03T09:56:32.437877Z","iopub.status.idle":"2022-07-03T09:56:32.450903Z","shell.execute_reply.started":"2022-07-03T09:56:32.43783Z","shell.execute_reply":"2022-07-03T09:56:32.449696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"$\\Rightarrow$ <font color=\"asparagus\"> There are no common rows among all these columns.<br> $\\Rightarrow$ *Side note*: There are quite a few outliers, in general. For example, there is an entry of a borrower with 6 million dollars as the annual income. But I did not see any shortcomings in the analysis by leaving it in. <br> $\\Rightarrow$ I eventually ended up leaving all the rows in, besides dropping so many unique rows(outliers of every column), the data would have shrunk drastically. <font>","metadata":{}},{"cell_type":"markdown","source":"# <font color='goldenrod'> III. Data Analysis </font>","metadata":{}},{"cell_type":"markdown","source":"### <font color='skyblue'>  III.1. Univariate analysis<font>","metadata":{}},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Observations and Comments*:<font><br>\n$\\Rightarrow$ <font color=\"asparagus\">Previously when we looked at box plots in *II.7.1*, we were mainly focused on the outliers. Let's look at them now to get some details about the variables.<br> $\\Rightarrow$ We will also look at the distribution plots for some numeric columns too. <font>","metadata":{}},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Segregating the columns into categorical and numerical explicitly* <font> ","metadata":{}},{"cell_type":"code","source":"cat_cols = [\"grade\", \"sub_grade\", \"term\", \"home_ownership\", \n            \"verification_status\", \"loan_status\", \n            \"purpose\", \"zip_code\", \"addr_state\", \"annual_inc_bins\", \n            \"funded_amnt_bins\", \"int_rate_bins\", \"emp_length_bins\", \n            \"delta\", \"delta_bins\", \"Pct_Payment_bins\"]","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:32.452635Z","iopub.execute_input":"2022-07-03T09:56:32.453895Z","iopub.status.idle":"2022-07-03T09:56:32.462633Z","shell.execute_reply.started":"2022-07-03T09:56:32.453849Z","shell.execute_reply":"2022-07-03T09:56:32.461485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"not_cat_cols = [col for col in df.columns if col not in cat_cols]","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:32.464165Z","iopub.execute_input":"2022-07-03T09:56:32.464536Z","iopub.status.idle":"2022-07-03T09:56:32.474853Z","shell.execute_reply.started":"2022-07-03T09:56:32.464505Z","shell.execute_reply":"2022-07-03T09:56:32.473719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_numeric = df.select_dtypes(include=np.number)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:32.476343Z","iopub.execute_input":"2022-07-03T09:56:32.477759Z","iopub.status.idle":"2022-07-03T09:56:32.492153Z","shell.execute_reply.started":"2022-07-03T09:56:32.477705Z","shell.execute_reply":"2022-07-03T09:56:32.490763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cont_cols = df_numeric.columns.to_list()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:32.493933Z","iopub.execute_input":"2022-07-03T09:56:32.494765Z","iopub.status.idle":"2022-07-03T09:56:32.500578Z","shell.execute_reply.started":"2022-07-03T09:56:32.494707Z","shell.execute_reply":"2022-07-03T09:56:32.499411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cont_cols","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:32.502619Z","iopub.execute_input":"2022-07-03T09:56:32.50346Z","iopub.status.idle":"2022-07-03T09:56:32.515138Z","shell.execute_reply.started":"2022-07-03T09:56:32.503413Z","shell.execute_reply":"2022-07-03T09:56:32.513934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color='skyblue'>  III.1.1. Box Plots contd.<font>","metadata":{}},{"cell_type":"code","source":"list(df.loan_status.unique())","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-07-03T09:56:32.516696Z","iopub.execute_input":"2022-07-03T09:56:32.517802Z","iopub.status.idle":"2022-07-03T09:56:32.531745Z","shell.execute_reply.started":"2022-07-03T09:56:32.517751Z","shell.execute_reply":"2022-07-03T09:56:32.530504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(5,5, figsize=(15,20))\nplt.subplots_adjust(left=0.1,\n                    bottom=0.1, \n                    right=0.9, \n                    top=0.9, \n                    wspace=0.4, \n                    hspace=0.4)\nfor col, ax in zip(cont_cols, axes.flatten()):\n    sns.boxplot(y=col, x= \"loan_status\", data=df, orient='v', ax=ax)\n    ax.tick_params(colors=\"black\", which=\"both\")\n    ax.set_xticklabels(['Fully Paid', 'Charged Off', 'Current'], rotation=45,color=\"black\")\n    ax.set(xlabel=None)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:32.534193Z","iopub.execute_input":"2022-07-03T09:56:32.53776Z","iopub.status.idle":"2022-07-03T09:56:36.774588Z","shell.execute_reply.started":"2022-07-03T09:56:32.537716Z","shell.execute_reply":"2022-07-03T09:56:36.77301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Observations and Comments*:<font><br>\n#### I am restricting to variables that might give us some insight about the data. If it is not revealing a lot, I will skip it in the comments below.\n    \n$\\Rightarrow$ <font color=\"asparagus\"> funded_amnt: <font>\n    \nFor the loans that are currently running, the median of the funded amount lies around 15000 dollars. Charged off and Fully Paid loans hover around 10,000 dollars.\n    \n$\\Rightarrow$ <font color=\"asparagus\"> term: <font>\n    \nCurrently running loans are borrowers that took 5 year loans, whereas *Charged Off* and *Fully Paid* loans have both 3 and 5 year loans.\n\n$\\Rightarrow$ <font color=\"asparagus\"> int_rate: <font>\n    \nInterest rate is high for currently running loans, *fully paid* loans have the lowest interest rates. This indicates that higher interest rate attracts more defaults.\n\n$\\Rightarrow$ <font color=\"asparagus\"> emp_length: <font>\n    \nEmployees with an experience of around 4 years seem to successfully pay off their loans, whereas the defaulters seem to have close to 5 years of experience. Currently running loans have more than 7 years of experience.\n\n$\\Rightarrow$ <font color=\"asparagus\"> annual_inc: <font>\n    \nThe ones with a lower annual income are more likely to defualt on their loans. When we look at the box plot of annual_inc vs *Fully Paid* loans, we see that it has borrowers with very less to really high incomes.\n\n$\\Rightarrow$ <font color=\"asparagus\"> dti: <font>\n    \ndti is around the same for all the loan statuses.    \n    \n$\\Rightarrow$ <font color=\"asparagus\"> inq_last_6mnths: <font>\n    \nThe borrowers who defaulted seem to enquire at least once in a space of 6 months. There are outliers though, so it is hard to conclude a lot from this.        \n\n$\\Rightarrow$ <font color=\"asparagus\"> total_payment: <font>\n    \nAs expected, the payment received is th least for the defaulters. Currently running loans seem to be of higher value than the ones that charged off. Again, there are outliers, but my comments are focused on median values across the board.\n    \n\n$\\Rightarrow$ <font color=\"asparagus\"> Percent Payment received: <font>\n    \nThis column that we derived also indicates the same thing as *total_payment*. *Charged Off* loans are in general paying less. Currently running loans seem to be close to 100% paid for.     \n\n$\\Rightarrow$ <font color=\"asparagus\"> Issue year: <font>\n    \nMost of the *fully paid* and *charged off* loans were issued some time in the year 2011. Currently running loans are close to 2012, late 2011. \n    \n$\\Rightarrow$ <font color=\"asparagus\"> Delta: <font>\n    \nThis is a column we derived earlier. To recall, it indicates the amount of time passed from issue date to last payment. Most of the *fully paid* loans' last payment was 3 years ago, with some outliers ~ 6 years, indicating that we might have data which includes loans given in the past 6 years. We can see *Charged Off* box plot suggesting that we might have data > 6 years as well(with the outliers). ","metadata":{}},{"cell_type":"markdown","source":"### <font color='skyblue'>  III.1.2. Probability Distribution <font>","metadata":{}},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Observations and Comments*:<font><br>\nFrom our box plot analysis, I think it makes sense looking at the probablity distribution of funded_amnt, annual income, interest rate, emp_length, percentage payment received just to get a glimpse of the pdf.","metadata":{}},{"cell_type":"code","source":"distplots_cols = [\"funded_amnt\", \"annual_inc\", \"int_rate\", \"Pct_Payment_Received\", \"emp_length\"]","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:36.776018Z","iopub.execute_input":"2022-07-03T09:56:36.776363Z","iopub.status.idle":"2022-07-03T09:56:36.781655Z","shell.execute_reply.started":"2022-07-03T09:56:36.776334Z","shell.execute_reply":"2022-07-03T09:56:36.780656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,7))\nfor idx, col in enumerate(distplots_cols):\n    ax = sns.displot(data=df, x=col, kde=True)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:36.783165Z","iopub.execute_input":"2022-07-03T09:56:36.783539Z","iopub.status.idle":"2022-07-03T09:56:44.337674Z","shell.execute_reply.started":"2022-07-03T09:56:36.783508Z","shell.execute_reply":"2022-07-03T09:56:44.336748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Observations and Comments*:<font><br>\n\n$\\Rightarrow$ <font color=\"asparagus\"> annual_inc: <font>\n    \nSeems like most of the borrowers have incomes on the lower end. With the spike somwhere around 50000 to 100,000, calling describe() on annual_inc will give a us a clear picture.\n\n$\\Rightarrow$ <font color=\"asparagus\"> int_rate: <font>\n    \nMost of the interest rate is in the range: 10-12.5%. With the highest spike at 7.5%\n\n$\\Rightarrow$ <font color=\"asparagus\"> emp_length: <font>\n    \nTwo spikes, one in the 0-2 years experience range and the other in the >10 years experience. \n<br> *Side note:* displots can also be plotted after z scoring for better detection of outliers. \n","metadata":{}},{"cell_type":"code","source":"df.annual_inc.describe()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:44.338934Z","iopub.execute_input":"2022-07-03T09:56:44.339544Z","iopub.status.idle":"2022-07-03T09:56:44.353258Z","shell.execute_reply.started":"2022-07-03T09:56:44.339509Z","shell.execute_reply":"2022-07-03T09:56:44.351997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <font color='goldenrod'> III.2. Bivariate analysis </font>","metadata":{}},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Comments*:<font> \n#### <font color=\"asparagus\"> $\\Rightarrow$ We've already studied the relation in between variables in the section *II.7. Correlation*.<br> $\\Rightarrow$ We identified strongly correlated variables, removed some redundant columns.<br> $\\Rightarrow$ We identified moderately and weakly correlated variables as well.<br> $\\Rightarrow$ But now it's time to find some good indicators with groupbys, pivot tables and plots<font> ","metadata":{}},{"cell_type":"markdown","source":"### <font color='skyblue'>  III.2.1. Categorical columns with a keen focus on loan_status <font> ","metadata":{}},{"cell_type":"markdown","source":"<font color=\"asparagus\"> Here are all the categorical columns. We won't group by all of them, but only ones that give us a good inference","metadata":{}},{"cell_type":"code","source":"cat_cols","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:44.355163Z","iopub.execute_input":"2022-07-03T09:56:44.355594Z","iopub.status.idle":"2022-07-03T09:56:44.363367Z","shell.execute_reply.started":"2022-07-03T09:56:44.355562Z","shell.execute_reply":"2022-07-03T09:56:44.362184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### $\\Rightarrow$ <font color=\"asparagus\"> III.2.1.1. Grade <font>","metadata":{}},{"cell_type":"code","source":"(df.groupby(by=[\"grade\"]).mean())","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:44.365174Z","iopub.execute_input":"2022-07-03T09:56:44.365552Z","iopub.status.idle":"2022-07-03T09:56:44.414087Z","shell.execute_reply.started":"2022-07-03T09:56:44.365521Z","shell.execute_reply":"2022-07-03T09:56:44.413275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(df.groupby(by=[\"loan_status\", \"grade\"]).mean())","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:44.415752Z","iopub.execute_input":"2022-07-03T09:56:44.416162Z","iopub.status.idle":"2022-07-03T09:56:44.474775Z","shell.execute_reply.started":"2022-07-03T09:56:44.416128Z","shell.execute_reply":"2022-07-03T09:56:44.473684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Observations and Comments*:<font><br>\n$\\Rightarrow$ <font color=\"asparagus\">You can see that borrowers with bad credit ratings tend to borrow more money. Let's try some pivot tables and then plot a pie chart. <font>","metadata":{}},{"cell_type":"code","source":"df.pivot_table(index=\"grade\",columns=[\"loan_status\"], values=\"funded_amnt\", aggfunc=\"mean\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:44.47608Z","iopub.execute_input":"2022-07-03T09:56:44.476498Z","iopub.status.idle":"2022-07-03T09:56:44.523512Z","shell.execute_reply.started":"2022-07-03T09:56:44.476469Z","shell.execute_reply":"2022-07-03T09:56:44.522454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### $\\Rightarrow$ <font color=\"asparagus\"> Let's get some numbers<font>\n1. How many people of a certain grade borrowed?\n2. How many of them defaulted, how many are currently paying/have fully paid?","metadata":{}},{"cell_type":"markdown","source":"#### $\\Rightarrow$ <font color=\"asparagus\">  Getting the grade-wise percentage for the three loan statuses we have","metadata":{}},{"cell_type":"markdown","source":"#### Let's look at the distribution of charged off loans based on grades\n\n","metadata":{}},{"cell_type":"code","source":"df_chargedOff = df[df[\"loan_status\"] == \"Charged Off\"].groupby(by=\"grade\").size()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:44.52595Z","iopub.execute_input":"2022-07-03T09:56:44.526448Z","iopub.status.idle":"2022-07-03T09:56:44.547138Z","shell.execute_reply.started":"2022-07-03T09:56:44.526413Z","shell.execute_reply":"2022-07-03T09:56:44.546278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_chargedOff","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:44.54876Z","iopub.execute_input":"2022-07-03T09:56:44.549659Z","iopub.status.idle":"2022-07-03T09:56:44.557248Z","shell.execute_reply.started":"2022-07-03T09:56:44.549615Z","shell.execute_reply":"2022-07-03T09:56:44.556433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grade_labels = sorted(df.grade.unique())","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:44.558463Z","iopub.execute_input":"2022-07-03T09:56:44.55949Z","iopub.status.idle":"2022-07-03T09:56:44.572486Z","shell.execute_reply.started":"2022-07-03T09:56:44.559445Z","shell.execute_reply":"2022-07-03T09:56:44.57158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplt.pie(df_chargedOff,labels=grade_labels,autopct='%.0f%%', textprops={'color':\"w\"})\nplt.show()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-07-03T09:56:44.574716Z","iopub.execute_input":"2022-07-03T09:56:44.575505Z","iopub.status.idle":"2022-07-03T09:56:44.758561Z","shell.execute_reply.started":"2022-07-03T09:56:44.57546Z","shell.execute_reply":"2022-07-03T09:56:44.756806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> $\\Rightarrow$ Observation and comments:\n1. Looking at this, it seems B,C D are more likely to default. But it kind of goes against our assumption: \"people with lower credit score are more likely to default\". \n2. It seems to be deceptive. We must see gradewise percent of people that have defaulted. ","metadata":{}},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> $\\Rightarrow$  Gradewise distribution","metadata":{}},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> $\\Rightarrow$ Before we proceed further, let's define a generic function that returns the percentage of charged Off, current and fully paid borrowers.<br> $\\Rightarrow$We must provide the bins across which we want to calucate the aforementioned percentags as an input argument. <br> $\\Rightarrow$Finally, we use this to plot pie charts","metadata":{}},{"cell_type":"code","source":"def calculate_groupwise_loan_status_percentage(bins_list, df, col):\n    groupwise_dist ={}\n    for curr_bin in bins_list:\n        nChargedOff = len(df[(df[col] == curr_bin) & (df[\"loan_status\"] == \"Charged Off\")])\n        nCurrent = len(df[(df[col] == curr_bin) & (df[\"loan_status\"] == \"Current\")])\n        nFullyPaid = len(df[(df[col] == curr_bin) & (df[\"loan_status\"] == \"Fully Paid\")])\n        totalNoOfPeople = len(df[df[col] == curr_bin])\n        if totalNoOfPeople > 0:\n            groupwise_dist[curr_bin] = [round(100 *nChargedOff/totalNoOfPeople,2), round(100 *nCurrent/totalNoOfPeople,2), round(100 *nFullyPaid/totalNoOfPeople,2)]\n        else:\n            groupwise_dist[curr_bin] = [0] *3\n    return groupwise_dist","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:44.760782Z","iopub.execute_input":"2022-07-03T09:56:44.764577Z","iopub.status.idle":"2022-07-03T09:56:44.780741Z","shell.execute_reply.started":"2022-07-03T09:56:44.764518Z","shell.execute_reply":"2022-07-03T09:56:44.77771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Defining another function that will return a pivot table, indexed by a particular column. It also also three new columns: pct_chargedOff, pct_current, pct_fullyPaid and return the grouped df. <br> This function will regularly be consumed by other columns too.","metadata":{}},{"cell_type":"code","source":"def get_grouped_df(df, col):\n    df_grouped = df.groupby([col, \"loan_status\"]).loan_status.count().unstack().fillna(0)\n    df_grouped[\"pct_chargedOff\"] = 100 *(df_grouped[\"Charged Off\"]) /( df_grouped[\"Charged Off\"] + df_grouped[\"Current\"] + df_grouped[\"Fully Paid\"])\n    df_grouped[\"pct_current\"] = 100 *(df_grouped[\"Current\"]) /( df_grouped[\"Charged Off\"] + df_grouped[\"Current\"] + df_grouped[\"Fully Paid\"])\n    df_grouped[\"pct_fullyPaid\"] = 100 *(df_grouped[\"Fully Paid\"]) /( df_grouped[\"Charged Off\"] + df_grouped[\"Current\"] + df_grouped[\"Fully Paid\"])\n    return df_grouped","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:44.784543Z","iopub.execute_input":"2022-07-03T09:56:44.785655Z","iopub.status.idle":"2022-07-03T09:56:44.795564Z","shell.execute_reply.started":"2022-07-03T09:56:44.785602Z","shell.execute_reply":"2022-07-03T09:56:44.794801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grade_wise_split = calculate_groupwise_loan_status_percentage(grade_labels, df, \"grade\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:44.796903Z","iopub.execute_input":"2022-07-03T09:56:44.797488Z","iopub.status.idle":"2022-07-03T09:56:45.240151Z","shell.execute_reply.started":"2022-07-03T09:56:44.797454Z","shell.execute_reply":"2022-07-03T09:56:45.238859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grade_wise_split","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:45.241728Z","iopub.execute_input":"2022-07-03T09:56:45.243115Z","iopub.status.idle":"2022-07-03T09:56:45.250964Z","shell.execute_reply.started":"2022-07-03T09:56:45.243075Z","shell.execute_reply":"2022-07-03T09:56:45.249663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plt.figure(figsize=(10,15))\nfor label in grade_labels:\n    plt.pie(grade_wise_split[label],labels=[\"Charged Off\", \"Current\", \"Fully Paid\"], autopct='%.0f%%', textprops={'color':\"w\"})\n    plt.title(f\"Grade {label}\")\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:45.252683Z","iopub.execute_input":"2022-07-03T09:56:45.253013Z","iopub.status.idle":"2022-07-03T09:56:46.172389Z","shell.execute_reply.started":"2022-07-03T09:56:45.252984Z","shell.execute_reply":"2022-07-03T09:56:46.171037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> $\\Rightarrow$ Observation and comments:\n1. Now the above pie charts tell the true story and it is in line with our initial assumption: Bad credit score = More likely to default<br>\n2. As you can see Grade A has only 6% charged off loans, and the lower you go the in grade, the higher the percentage. Eg: Grade G: Charged off percentage: 32%","metadata":{}},{"cell_type":"code","source":"# I can safely append grade to the indicators list based on our analysis above\nindicators.append(\"grade\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:46.17457Z","iopub.execute_input":"2022-07-03T09:56:46.176012Z","iopub.status.idle":"2022-07-03T09:56:46.182744Z","shell.execute_reply.started":"2022-07-03T09:56:46.175956Z","shell.execute_reply":"2022-07-03T09:56:46.180793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### $\\Rightarrow$ <font color=\"asparagus\"> III.2.1.2. Home Ownership <font>","metadata":{}},{"cell_type":"code","source":"(df.groupby(by=[\"home_ownership\", \"loan_status\"]).mean())","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:46.185075Z","iopub.execute_input":"2022-07-03T09:56:46.185718Z","iopub.status.idle":"2022-07-03T09:56:46.273773Z","shell.execute_reply.started":"2022-07-03T09:56:46.185664Z","shell.execute_reply":"2022-07-03T09:56:46.27284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Observations and comments* <font>\n$\\Rightarrow$ The table above does not seem to give us a good picture. Can't seem to get a good segragation.<br> $\\Rightarrow$ Let's define another function that will return a pivot table, indexed by a particular column. It also adds three new columns: pct_chargedOff, pct_current, pct_fullyPaid and return the grouped df. <br> $\\Rightarrow$This function will regularly be consumed by other columns too.\n","metadata":{}},{"cell_type":"code","source":"home_owner_group = get_grouped_df(df, \"home_ownership\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:46.275076Z","iopub.execute_input":"2022-07-03T09:56:46.276044Z","iopub.status.idle":"2022-07-03T09:56:46.311632Z","shell.execute_reply.started":"2022-07-03T09:56:46.276002Z","shell.execute_reply":"2022-07-03T09:56:46.310479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"home_owner_group","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:46.313098Z","iopub.execute_input":"2022-07-03T09:56:46.313458Z","iopub.status.idle":"2022-07-03T09:56:46.32556Z","shell.execute_reply.started":"2022-07-03T09:56:46.313426Z","shell.execute_reply":"2022-07-03T09:56:46.324637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Observations and comments* <font>\n$\\Rightarrow$ The above table looks cleaner. But there doesn't seem to be any pattern emerging. I was hoping to see borrowers with mortgage and rent to have more defaults, but that's not the case. *OTHER* has the highest charged off percentage.<br> $\\Rightarrow$  Home_ownership is probably not a good indicator for default","metadata":{}},{"cell_type":"markdown","source":"##### $\\Rightarrow$ <font color=\"asparagus\"> III.2.1.3. Verification Status","metadata":{}},{"cell_type":"markdown","source":" #### <font color=\"asparagus\" > <br> 1. Not verified: Default Percentage: 1266% <br> 2. Source Verified: 14.36% <br> 3. Verified: 16.01% <font>","metadata":{}},{"cell_type":"code","source":"(df.groupby(by=[\"verification_status\", \"loan_status\"]).mean())","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:46.327174Z","iopub.execute_input":"2022-07-03T09:56:46.327555Z","iopub.status.idle":"2022-07-03T09:56:46.393495Z","shell.execute_reply.started":"2022-07-03T09:56:46.327524Z","shell.execute_reply":"2022-07-03T09:56:46.392542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"verif_status_group = get_grouped_df(df,\"verification_status\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:46.394569Z","iopub.execute_input":"2022-07-03T09:56:46.39535Z","iopub.status.idle":"2022-07-03T09:56:46.433076Z","shell.execute_reply.started":"2022-07-03T09:56:46.395249Z","shell.execute_reply":"2022-07-03T09:56:46.431838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"verif_status_group","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:46.434513Z","iopub.execute_input":"2022-07-03T09:56:46.434992Z","iopub.status.idle":"2022-07-03T09:56:46.449045Z","shell.execute_reply.started":"2022-07-03T09:56:46.434957Z","shell.execute_reply":"2022-07-03T09:56:46.447561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Observations and comments* <font>\n$\\Rightarrow$ No pattern emerging here other. ","metadata":{}},{"cell_type":"markdown","source":"##### $\\Rightarrow$ <font color=\"asparagus\"> III.2.1.4. Purpose","metadata":{}},{"cell_type":"code","source":"(df.groupby(by=[\"purpose\"]).mean())","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:46.451233Z","iopub.execute_input":"2022-07-03T09:56:46.451777Z","iopub.status.idle":"2022-07-03T09:56:46.504932Z","shell.execute_reply.started":"2022-07-03T09:56:46.45171Z","shell.execute_reply":"2022-07-03T09:56:46.503618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"purpose_grouped = get_grouped_df(df,\"purpose\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:46.506413Z","iopub.execute_input":"2022-07-03T09:56:46.507216Z","iopub.status.idle":"2022-07-03T09:56:46.544049Z","shell.execute_reply.started":"2022-07-03T09:56:46.507156Z","shell.execute_reply":"2022-07-03T09:56:46.542644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"purpose_grouped","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:46.54605Z","iopub.execute_input":"2022-07-03T09:56:46.546443Z","iopub.status.idle":"2022-07-03T09:56:46.562959Z","shell.execute_reply.started":"2022-07-03T09:56:46.54641Z","shell.execute_reply":"2022-07-03T09:56:46.56167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Observations and comments* <font>\nCertain purposes pop out. Let's try a pie chart.","metadata":{}},{"cell_type":"code","source":"purpose_labels = sorted(df.purpose.unique())","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:46.564033Z","iopub.execute_input":"2022-07-03T09:56:46.564434Z","iopub.status.idle":"2022-07-03T09:56:46.577036Z","shell.execute_reply.started":"2022-07-03T09:56:46.564388Z","shell.execute_reply":"2022-07-03T09:56:46.576096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"purpose_dist = calculate_groupwise_loan_status_percentage(purpose_labels, df, \"purpose\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:46.578546Z","iopub.execute_input":"2022-07-03T09:56:46.578888Z","iopub.status.idle":"2022-07-03T09:56:47.400182Z","shell.execute_reply.started":"2022-07-03T09:56:46.578856Z","shell.execute_reply":"2022-07-03T09:56:47.39873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting pie chart\nfor label in purpose_labels:\n    plt.pie(purpose_dist[label],labels=[\"Charged Off\", \"Current\", \"Fully Paid\"], autopct='%.0f%%', textprops={'color':\"black\"})\n    plt.title(f\" Purpose: {label}\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:47.402178Z","iopub.execute_input":"2022-07-03T09:56:47.402688Z","iopub.status.idle":"2022-07-03T09:56:49.325692Z","shell.execute_reply.started":"2022-07-03T09:56:47.402654Z","shell.execute_reply":"2022-07-03T09:56:49.323959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Observations and Comments*:<font> \nSmall business borrowers seem to default a lot more. $\\Rightarrow 26%.<br> The others are fairly even around 80 - 85%.<br> Loans borrowed for wedding seem to have the lowest default percentage\n#### <font color=\"asparagus\"> This can also be a good indicator to decide whether the loan is going to be defaulted or not.<font>","metadata":{}},{"cell_type":"code","source":"# I can safely append purpose to the indicators list based on our analysis above\nindicators.append(\"purpose\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:49.327901Z","iopub.execute_input":"2022-07-03T09:56:49.328573Z","iopub.status.idle":"2022-07-03T09:56:49.335605Z","shell.execute_reply.started":"2022-07-03T09:56:49.328513Z","shell.execute_reply":"2022-07-03T09:56:49.334266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> $\\Rightarrow$ A stacked bar plot says the same thing. Small businesses have more percent of charged off","metadata":{}},{"cell_type":"code","source":"loan_labels = [\"Charged Off\", \"Current\", \"Fully Paid\"]\nchargedOff = []\nfor label in purpose_labels:\n    chargedOff.append(purpose_dist[label][0])\nchargedOff = np.array(chargedOff) \n\ncurrent = []\nfor label in purpose_labels:\n    current.append(purpose_dist[label][1])\ncurrent = np.array(current) \n\nFully = []\nfor label in purpose_labels:\n    Fully.append(purpose_dist[label][2])\nFully = np.array(Fully)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:49.337758Z","iopub.execute_input":"2022-07-03T09:56:49.338605Z","iopub.status.idle":"2022-07-03T09:56:49.350648Z","shell.execute_reply.started":"2022-07-03T09:56:49.338557Z","shell.execute_reply":"2022-07-03T09:56:49.34929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot stacked bar\nax = plt.figure(figsize=(10,10))\nplt.bar(purpose_labels, Fully, color='mediumseagreen')\nplt.bar(purpose_labels, current, bottom=Fully, color='tab:olive')\nplt.bar(purpose_labels, chargedOff, bottom=Fully+current, color=(0.5,0.3,0.3))\nplt.xticks(rotation=\"vertical\")\nplt.yticks(color=(0.7,0.9,0.9))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:49.352742Z","iopub.execute_input":"2022-07-03T09:56:49.354531Z","iopub.status.idle":"2022-07-03T09:56:49.67607Z","shell.execute_reply.started":"2022-07-03T09:56:49.35446Z","shell.execute_reply":"2022-07-03T09:56:49.675117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### $\\Rightarrow$ <font color=\"asparagus\"> III.2.1.5. Employee Experience","metadata":{}},{"cell_type":"code","source":"df.pivot_table(index=[\"emp_length_bins\"], columns=[\"loan_status\"], values=\"funded_amnt\", aggfunc=\"mean\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:49.677794Z","iopub.execute_input":"2022-07-03T09:56:49.678575Z","iopub.status.idle":"2022-07-03T09:56:49.713155Z","shell.execute_reply.started":"2022-07-03T09:56:49.678528Z","shell.execute_reply":"2022-07-03T09:56:49.711975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> $\\Rightarrow$ The more experienced borrowers tend to borrow more money <font>","metadata":{}},{"cell_type":"code","source":"emp_exp_list = sorted(df.emp_length_bins.unique().to_list())","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:49.714879Z","iopub.execute_input":"2022-07-03T09:56:49.715604Z","iopub.status.idle":"2022-07-03T09:56:49.721768Z","shell.execute_reply.started":"2022-07-03T09:56:49.715559Z","shell.execute_reply":"2022-07-03T09:56:49.720922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emp_exp_wise_dist = calculate_groupwise_loan_status_percentage(emp_exp_list, df, \"emp_length_bins\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:49.723343Z","iopub.execute_input":"2022-07-03T09:56:49.724Z","iopub.status.idle":"2022-07-03T09:56:49.957726Z","shell.execute_reply.started":"2022-07-03T09:56:49.723957Z","shell.execute_reply":"2022-07-03T09:56:49.956534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emp_exp_wise_dist","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:49.959125Z","iopub.execute_input":"2022-07-03T09:56:49.959634Z","iopub.status.idle":"2022-07-03T09:56:49.967057Z","shell.execute_reply.started":"2022-07-03T09:56:49.959592Z","shell.execute_reply":"2022-07-03T09:56:49.965788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting pie chart\nfor label in emp_exp_list:\n    plt.pie(emp_exp_wise_dist[label],labels=[\"Charged Off\", \"Current\", \"Fully Paid\"], autopct='%.0f%%', textprops={'color':\"w\"})\n    plt.title(f\"Emp experience: {label}\")\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:49.968346Z","iopub.execute_input":"2022-07-03T09:56:49.968675Z","iopub.status.idle":"2022-07-03T09:56:50.77714Z","shell.execute_reply.started":"2022-07-03T09:56:49.968646Z","shell.execute_reply":"2022-07-03T09:56:50.775833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> Shouldn't people with less experience default more often? But I do not observe any pattern here.<font> <br>","metadata":{}},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> The following cells will help give us better insight","metadata":{}},{"cell_type":"code","source":"emp_exp_group = get_grouped_df(df,\"emp_length_bins\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:50.778906Z","iopub.execute_input":"2022-07-03T09:56:50.779687Z","iopub.status.idle":"2022-07-03T09:56:50.828545Z","shell.execute_reply.started":"2022-07-03T09:56:50.779629Z","shell.execute_reply":"2022-07-03T09:56:50.821626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emp_exp_group","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:50.833012Z","iopub.execute_input":"2022-07-03T09:56:50.834276Z","iopub.status.idle":"2022-07-03T09:56:50.861605Z","shell.execute_reply.started":"2022-07-03T09:56:50.834192Z","shell.execute_reply":"2022-07-03T09:56:50.859825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emp_exp_group.sort_values([\"pct_chargedOff\"], ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:50.863248Z","iopub.execute_input":"2022-07-03T09:56:50.864306Z","iopub.status.idle":"2022-07-03T09:56:50.881496Z","shell.execute_reply.started":"2022-07-03T09:56:50.864261Z","shell.execute_reply":"2022-07-03T09:56:50.880259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Observations and Comments*<br>$\\Rightarrow$ I see people with more than 10 years of experience, defaulting more often than people with less experience.<br> $\\Rightarrow$ But the increase in percentage is very small. For the most part the percentage is ~ 15%<br> $\\Rightarrow$ Can't really put emp_length as a very strong indicator of default.<br> $\\Rightarrow$<font color=\"asparagus\"> *Side Note*: Borrowers with 8-10 experience have the lowest percent of default <font>","metadata":{}},{"cell_type":"markdown","source":"##### $\\Rightarrow$ <font color=\"asparagus\"> III.2.1.6. Annual Income","metadata":{}},{"cell_type":"code","source":"annual_inc_labels = sorted(df.annual_inc_bins.unique())","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:50.883065Z","iopub.execute_input":"2022-07-03T09:56:50.883895Z","iopub.status.idle":"2022-07-03T09:56:50.897388Z","shell.execute_reply.started":"2022-07-03T09:56:50.88386Z","shell.execute_reply":"2022-07-03T09:56:50.896191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"annual_inc_wise_dist = calculate_groupwise_loan_status_percentage(annual_inc_labels, df, \"annual_inc_bins\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:50.9011Z","iopub.execute_input":"2022-07-03T09:56:50.903373Z","iopub.status.idle":"2022-07-03T09:56:51.132152Z","shell.execute_reply.started":"2022-07-03T09:56:50.903313Z","shell.execute_reply":"2022-07-03T09:56:51.131344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting pie chart\nfor label in annual_inc_labels:\n    plt.pie(annual_inc_wise_dist[label],labels=[\"Charged Off\", \"Current\", \"Fully Paid\"], autopct='%.0f%%', textprops={'color':\"w\"})\n    plt.title(f\"Annual inc(thousands): {label}\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:51.133472Z","iopub.execute_input":"2022-07-03T09:56:51.134609Z","iopub.status.idle":"2022-07-03T09:56:51.968824Z","shell.execute_reply.started":"2022-07-03T09:56:51.134566Z","shell.execute_reply":"2022-07-03T09:56:51.967388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Observations and Comments*:<font> \nThe percentage of defaulting borrowers with annual income in between $0-$20k is double that of those make more than 100k dollars. We can further split >100k and potentially observe the same pattern","metadata":{}},{"cell_type":"code","source":"# I can safely append annual inc to the indicators list based on our analysis above\nindicators.append(\"annual_inc\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:51.970404Z","iopub.execute_input":"2022-07-03T09:56:51.9715Z","iopub.status.idle":"2022-07-03T09:56:51.980985Z","shell.execute_reply.started":"2022-07-03T09:56:51.971443Z","shell.execute_reply":"2022-07-03T09:56:51.979362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"indicators","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:51.983105Z","iopub.execute_input":"2022-07-03T09:56:51.984043Z","iopub.status.idle":"2022-07-03T09:56:51.993836Z","shell.execute_reply.started":"2022-07-03T09:56:51.983989Z","shell.execute_reply":"2022-07-03T09:56:51.992614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### $\\Rightarrow$ <font color=\"asparagus\"> III.2.1.7. Funded Amount","metadata":{}},{"cell_type":"code","source":"funded_amnt_labels = sorted(df.funded_amnt_bins.unique())","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:51.99622Z","iopub.execute_input":"2022-07-03T09:56:51.99715Z","iopub.status.idle":"2022-07-03T09:56:52.00572Z","shell.execute_reply.started":"2022-07-03T09:56:51.997097Z","shell.execute_reply":"2022-07-03T09:56:52.004406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"funded_amnt_labels","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:52.007939Z","iopub.execute_input":"2022-07-03T09:56:52.00909Z","iopub.status.idle":"2022-07-03T09:56:52.01977Z","shell.execute_reply.started":"2022-07-03T09:56:52.009036Z","shell.execute_reply":"2022-07-03T09:56:52.018033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"funded_amnt_dist = calculate_groupwise_loan_status_percentage(funded_amnt_labels, df, \"funded_amnt_bins\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:52.022482Z","iopub.execute_input":"2022-07-03T09:56:52.023558Z","iopub.status.idle":"2022-07-03T09:56:52.279262Z","shell.execute_reply.started":"2022-07-03T09:56:52.023501Z","shell.execute_reply":"2022-07-03T09:56:52.278177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"funded_amnt_dist","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:52.280767Z","iopub.execute_input":"2022-07-03T09:56:52.281461Z","iopub.status.idle":"2022-07-03T09:56:52.289648Z","shell.execute_reply.started":"2022-07-03T09:56:52.281415Z","shell.execute_reply":"2022-07-03T09:56:52.288587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting pie chart\nfor label in funded_amnt_labels:\n    plt.pie(funded_amnt_dist[label],labels=[\"Charged Off\", \"Current\", \"Fully Paid\"], autopct='%.0f%%', textprops={'color':\"w\"})\n    plt.title(f\" funded_amount(1000s): {label}\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:52.291124Z","iopub.execute_input":"2022-07-03T09:56:52.29148Z","iopub.status.idle":"2022-07-03T09:56:53.226967Z","shell.execute_reply.started":"2022-07-03T09:56:52.29145Z","shell.execute_reply":"2022-07-03T09:56:53.225402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> $\\Rightarrow$ Observations:\n1. Higher the amount, more is the charged off percentage. Eg: In the range 30000-35000: the percentage of borrowers who charged off is 22%\n2. Charged off percentage for 0-5000 is 14%.\n3. Adding this to the list of indicators","metadata":{}},{"cell_type":"code","source":"indicators.append(\"funded_amnt\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:53.22899Z","iopub.execute_input":"2022-07-03T09:56:53.230276Z","iopub.status.idle":"2022-07-03T09:56:53.235604Z","shell.execute_reply.started":"2022-07-03T09:56:53.230219Z","shell.execute_reply":"2022-07-03T09:56:53.234369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"indicators","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:53.237269Z","iopub.execute_input":"2022-07-03T09:56:53.238214Z","iopub.status.idle":"2022-07-03T09:56:53.252019Z","shell.execute_reply.started":"2022-07-03T09:56:53.238145Z","shell.execute_reply":"2022-07-03T09:56:53.250774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### $\\Rightarrow$ <font color=\"asparagus\"> III.2.1.8. Rate of Interest","metadata":{}},{"cell_type":"code","source":"int_rate_labels = (df.int_rate_bins.unique())","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:53.254284Z","iopub.execute_input":"2022-07-03T09:56:53.255517Z","iopub.status.idle":"2022-07-03T09:56:53.263039Z","shell.execute_reply.started":"2022-07-03T09:56:53.255468Z","shell.execute_reply":"2022-07-03T09:56:53.262237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"int_rate_dist = calculate_groupwise_loan_status_percentage(int_rate_labels, df, \"int_rate_bins\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:53.266004Z","iopub.execute_input":"2022-07-03T09:56:53.266771Z","iopub.status.idle":"2022-07-03T09:56:53.496923Z","shell.execute_reply.started":"2022-07-03T09:56:53.266724Z","shell.execute_reply":"2022-07-03T09:56:53.495703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting pie chart\nfor label in int_rate_labels:\n    plt.pie(int_rate_dist[label],labels=[\"Charged Off\", \"Current\", \"Fully Paid\"], autopct='%.0f%%', textprops={'color':\"w\"})\n    plt.title(f\" int rate: {label}%\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:53.498439Z","iopub.execute_input":"2022-07-03T09:56:53.498795Z","iopub.status.idle":"2022-07-03T09:56:54.64922Z","shell.execute_reply.started":"2022-07-03T09:56:53.498762Z","shell.execute_reply":"2022-07-03T09:56:54.647938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Observations and Comments*:<font> \n$\\Rightarrow$ We can conclude that higher interest rates, attract more defaults. Eg: For int_rate in the range 0-8%, % charged off = 5%<br>$\\Rightarrow$ int_rate >16% has % charged Off = 27% <font color=\"asparagus\"> **A huge increase**<font>","metadata":{}},{"cell_type":"code","source":"# I can safely append int_rate to the indicators list based on our analysis above\nindicators.append(\"int_rate\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:54.650951Z","iopub.execute_input":"2022-07-03T09:56:54.651816Z","iopub.status.idle":"2022-07-03T09:56:54.657419Z","shell.execute_reply.started":"2022-07-03T09:56:54.651762Z","shell.execute_reply":"2022-07-03T09:56:54.656185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"indicators","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:54.659128Z","iopub.execute_input":"2022-07-03T09:56:54.660477Z","iopub.status.idle":"2022-07-03T09:56:54.674332Z","shell.execute_reply.started":"2022-07-03T09:56:54.660416Z","shell.execute_reply":"2022-07-03T09:56:54.672962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### $\\Rightarrow$ <font color=\"asparagus\"> III.2.1.9. Public records","metadata":{}},{"cell_type":"code","source":"df.pub_rec.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:54.676509Z","iopub.execute_input":"2022-07-03T09:56:54.677692Z","iopub.status.idle":"2022-07-03T09:56:54.693691Z","shell.execute_reply.started":"2022-07-03T09:56:54.677628Z","shell.execute_reply":"2022-07-03T09:56:54.692342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pub_rec_group = get_grouped_df(df,\"pub_rec\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:54.695938Z","iopub.execute_input":"2022-07-03T09:56:54.697737Z","iopub.status.idle":"2022-07-03T09:56:54.738485Z","shell.execute_reply.started":"2022-07-03T09:56:54.697678Z","shell.execute_reply":"2022-07-03T09:56:54.737553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pub_rec_group","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:54.739984Z","iopub.execute_input":"2022-07-03T09:56:54.74058Z","iopub.status.idle":"2022-07-03T09:56:54.753322Z","shell.execute_reply.started":"2022-07-03T09:56:54.740548Z","shell.execute_reply":"2022-07-03T09:56:54.752171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pub_rec_group.sort_values(\"pct_chargedOff\", ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:54.754752Z","iopub.execute_input":"2022-07-03T09:56:54.755463Z","iopub.status.idle":"2022-07-03T09:56:54.768579Z","shell.execute_reply.started":"2022-07-03T09:56:54.755424Z","shell.execute_reply":"2022-07-03T09:56:54.767513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> pub_rec according to the data dictionary:  Number of derogatory public records. <font> \n$\\Rightarrow$ We might think that more the derogatory records, higher the defaults. But that's not what we see in this data.<br> $\\Rightarrow$ Borrowers with 3 and 4 pub_rec have fully paid, whereas borrowers with only 1 derogatory record have defaulted more often than those with 2 derogatory records\nTherefore, I cannot add this as to the list of indicators","metadata":{}},{"cell_type":"markdown","source":"##### <font color=\"asparagus\"> $\\Rightarrow$ III.2.1.10. Number of inquiries in the last 6 months","metadata":{}},{"cell_type":"code","source":"inq_6mnths_group = get_grouped_df(df, \"inq_last_6mths\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:54.769835Z","iopub.execute_input":"2022-07-03T09:56:54.770432Z","iopub.status.idle":"2022-07-03T09:56:54.796892Z","shell.execute_reply.started":"2022-07-03T09:56:54.770399Z","shell.execute_reply":"2022-07-03T09:56:54.79576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inq_6mnths_group","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:54.798137Z","iopub.execute_input":"2022-07-03T09:56:54.798507Z","iopub.status.idle":"2022-07-03T09:56:54.811273Z","shell.execute_reply.started":"2022-07-03T09:56:54.798475Z","shell.execute_reply":"2022-07-03T09:56:54.810111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inq_6mnths_group.sort_values([\"pct_chargedOff\"], ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:54.812709Z","iopub.execute_input":"2022-07-03T09:56:54.81306Z","iopub.status.idle":"2022-07-03T09:56:54.83298Z","shell.execute_reply.started":"2022-07-03T09:56:54.813029Z","shell.execute_reply":"2022-07-03T09:56:54.832053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> $\\Rightarrow$ Now this is a good indicator of default. Borrowers who have inquired more in the past 6 months are more likely to default","metadata":{}},{"cell_type":"code","source":"indicators.append(\"inq_last_6mnths\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:54.834419Z","iopub.execute_input":"2022-07-03T09:56:54.834759Z","iopub.status.idle":"2022-07-03T09:56:54.845488Z","shell.execute_reply.started":"2022-07-03T09:56:54.834729Z","shell.execute_reply":"2022-07-03T09:56:54.844484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> $\\Rightarrow$ III.2.1.11. State Address","metadata":{}},{"cell_type":"code","source":"addr_state_group = get_grouped_df(df, \"addr_state\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:54.84745Z","iopub.execute_input":"2022-07-03T09:56:54.848038Z","iopub.status.idle":"2022-07-03T09:56:54.88859Z","shell.execute_reply.started":"2022-07-03T09:56:54.847992Z","shell.execute_reply":"2022-07-03T09:56:54.887666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"addr_state_group.sort_values(\"pct_chargedOff\", ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:54.890177Z","iopub.execute_input":"2022-07-03T09:56:54.890642Z","iopub.status.idle":"2022-07-03T09:56:54.910883Z","shell.execute_reply.started":"2022-07-03T09:56:54.890598Z","shell.execute_reply":"2022-07-03T09:56:54.909937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,15))\nsns.barplot(x=addr_state_group.index, y=addr_state_group[\"pct_chargedOff\"])\nplt.xticks(rotation=\"vertical\")\n# plt.yticks(color=\"w\")\nplt.show()\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:54.912314Z","iopub.execute_input":"2022-07-03T09:56:54.912634Z","iopub.status.idle":"2022-07-03T09:56:55.609391Z","shell.execute_reply.started":"2022-07-03T09:56:54.912605Z","shell.execute_reply":"2022-07-03T09:56:55.60833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> Borrowers from the state of Nebraska(NE) are more likely to default than others. $\\Rightarrow$ 60% <font> <br> We can add addr_state to the list of indicators as well","metadata":{}},{"cell_type":"code","source":"indicators.append(\"addr_state\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:55.610863Z","iopub.execute_input":"2022-07-03T09:56:55.611316Z","iopub.status.idle":"2022-07-03T09:56:55.616499Z","shell.execute_reply.started":"2022-07-03T09:56:55.611284Z","shell.execute_reply":"2022-07-03T09:56:55.615274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"indicators","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:55.61847Z","iopub.execute_input":"2022-07-03T09:56:55.618947Z","iopub.status.idle":"2022-07-03T09:56:55.631322Z","shell.execute_reply.started":"2022-07-03T09:56:55.6189Z","shell.execute_reply":"2022-07-03T09:56:55.630443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> $\\Rightarrow$ III.2.1.12. Loan Term","metadata":{}},{"cell_type":"code","source":"term_grouped = get_grouped_df(df,\"term\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:55.632824Z","iopub.execute_input":"2022-07-03T09:56:55.633167Z","iopub.status.idle":"2022-07-03T09:56:55.66379Z","shell.execute_reply.started":"2022-07-03T09:56:55.633136Z","shell.execute_reply":"2022-07-03T09:56:55.662769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"term_grouped.sort_values(\"pct_chargedOff\", ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:55.665102Z","iopub.execute_input":"2022-07-03T09:56:55.665451Z","iopub.status.idle":"2022-07-03T09:56:55.680361Z","shell.execute_reply.started":"2022-07-03T09:56:55.665421Z","shell.execute_reply":"2022-07-03T09:56:55.679172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> Borrowing money for a term period of 5 years are twice as likely to default than those whose term period is 3 years.(22.6% vs 11.09%). <font>\nWe need to understand why though. What's so specific about the 5 year plan, that makes borrowers default?<br> Let's do a bivariate analysis of term period with other variables in our indicators' list.","metadata":{}},{"cell_type":"code","source":"sns.boxplot(y=\"Pct_Payment_Received\", x=\"term\", data=df)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:55.681908Z","iopub.execute_input":"2022-07-03T09:56:55.682752Z","iopub.status.idle":"2022-07-03T09:56:55.864875Z","shell.execute_reply.started":"2022-07-03T09:56:55.682699Z","shell.execute_reply":"2022-07-03T09:56:55.863808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Observation and comments*<font>\nIt makes sense that the amount of payment received is less for the 5 year loan since they default more often","metadata":{}},{"cell_type":"markdown","source":"We know that the worse your credit rating(grade), the more likely it is that you will default. But I can't see much of a pattern here","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.boxplot(y=\"grade\", x=\"term\", data=df)\n#plt.xticks(color=\"w\")\n#plt.yticks(color=\"w\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:55.86619Z","iopub.execute_input":"2022-07-03T09:56:55.86654Z","iopub.status.idle":"2022-07-03T09:56:56.186231Z","shell.execute_reply.started":"2022-07-03T09:56:55.86651Z","shell.execute_reply":"2022-07-03T09:56:56.185113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.boxplot(y=\"annual_inc_bins\", x=\"term\", data=df)\n#plt.xticks(color=\"w\")\n#plt.yticks(color=\"w\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:56.211649Z","iopub.execute_input":"2022-07-03T09:56:56.212037Z","iopub.status.idle":"2022-07-03T09:56:56.492808Z","shell.execute_reply.started":"2022-07-03T09:56:56.212006Z","shell.execute_reply":"2022-07-03T09:56:56.49163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Observation and comments*<font>\nFrom our previous analysis, lower the income the more likely it is that the borrower will default. \nThe above plot shows just that. Borrowers with income in the range \\$0-\\$40,000 opt for the 5 year loan, which explains the increase of defaults in the 5 year plan","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.boxplot(y=\"purpose\", x=\"term\", data=df)\n#plt.xticks(color=\"w\")\n#plt.yticks(color=\"w\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:56.494376Z","iopub.execute_input":"2022-07-03T09:56:56.494689Z","iopub.status.idle":"2022-07-03T09:56:56.936915Z","shell.execute_reply.started":"2022-07-03T09:56:56.494652Z","shell.execute_reply":"2022-07-03T09:56:56.935595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Observation and comments*<font>\nWe know loans for the purpose of small businesses tend to default more, but the boxplot says that they go for both 3 and 5 year terms. May be a percentage will help?","metadata":{}},{"cell_type":"code","source":"chargedOffSum = len(df[(df.purpose == \"small_business\") & (df[\"loan_status\"] ==\"Charged Off\")])\nn5yrSum = len(df[(df.purpose == \"small_business\") & (df[\"loan_status\"] ==\"Charged Off\") & (df.term == 5)])\nn3yrSum = len(df[(df.purpose == \"small_business\") & (df[\"loan_status\"] ==\"Charged Off\") & (df.term == 3)])\n","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:56.938276Z","iopub.execute_input":"2022-07-03T09:56:56.938609Z","iopub.status.idle":"2022-07-03T09:56:56.995277Z","shell.execute_reply.started":"2022-07-03T09:56:56.93858Z","shell.execute_reply":"2022-07-03T09:56:56.994113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"100* n5yrSum/chargedOffSum, 100* n3yrSum/chargedOffSum\n","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:56.996602Z","iopub.execute_input":"2022-07-03T09:56:56.996901Z","iopub.status.idle":"2022-07-03T09:56:57.005454Z","shell.execute_reply.started":"2022-07-03T09:56:56.996874Z","shell.execute_reply":"2022-07-03T09:56:57.003969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Observation and comments*<font>\nNo, it seems small business borrowers have been given 3 year term","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.boxplot(y=\"funded_amnt_bins\", x=\"term\", data=df)\n#plt.xticks(color=\"w\")\n#plt.yticks(color=\"w\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:57.006838Z","iopub.execute_input":"2022-07-03T09:56:57.007167Z","iopub.status.idle":"2022-07-03T09:56:57.301942Z","shell.execute_reply.started":"2022-07-03T09:56:57.007139Z","shell.execute_reply":"2022-07-03T09:56:57.301094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Observation and comments*<font>\nFrom before, higher the funded amount, higher the charged off percentage. But it seems I cannot get any pattern here.<br> But we also know that higher the funded amount, higher is the interest given to them. <br>So there might be something when we do a boxplot of term with interest rate","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.boxplot(y=\"int_rate\", x=\"term\", data=df)\n#plt.xticks(color=\"w\")\n#plt.yticks(color=\"w\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:57.303169Z","iopub.execute_input":"2022-07-03T09:56:57.303737Z","iopub.status.idle":"2022-07-03T09:56:57.510462Z","shell.execute_reply.started":"2022-07-03T09:56:57.303699Z","shell.execute_reply":"2022-07-03T09:56:57.509242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Observation and comments*<font>\nBingo! As suspected, the interest rate is high for 5 year term! And we know that higher interest rates attract more defaults. Therefore, this is another contributing factor to the higher number of defaults in the 5 year loans(double that of 3 year loans)","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.boxplot(y=\"inq_last_6mths\", x=\"term\", data=df)\n#plt.xticks(color=\"w\")\n#plt.yticks(color=\"w\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:57.512332Z","iopub.execute_input":"2022-07-03T09:56:57.512701Z","iopub.status.idle":"2022-07-03T09:56:57.713817Z","shell.execute_reply.started":"2022-07-03T09:56:57.512668Z","shell.execute_reply":"2022-07-03T09:56:57.712985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Observation and comments*<font>\nMedian of inq_last_6mths is 1 for the 5 year loan. But there are outliers in the 3 year loan as well. Can't really conclude much. This is a contributing factor but not very strong, I guess.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,50))\nsns.boxplot(y=\"addr_state\", x=\"term\", data=df)\n#plt.xticks(color=\"w\")\n#plt.yticks(color=\"w\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:57.71501Z","iopub.execute_input":"2022-07-03T09:56:57.71557Z","iopub.status.idle":"2022-07-03T09:56:59.156436Z","shell.execute_reply.started":"2022-07-03T09:56:57.715532Z","shell.execute_reply":"2022-07-03T09:56:59.155244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Observation and comments*<font>\nCan't conclude much here. The term is all over the place. I mainly wanted to see what's going on in NE, NA, AK, SD since they have the highest defaults. In fact, NE, the state with the highest defaults has purely 3 year loans","metadata":{}},{"cell_type":"markdown","source":"##### <font color=\"asparagus\"> $\\Rightarrow$ III.2.1.13. Delta_bins","metadata":{}},{"cell_type":"code","source":"delta_bins_group = get_grouped_df(df,\"delta_bins\")","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:59.157848Z","iopub.execute_input":"2022-07-03T09:56:59.158856Z","iopub.status.idle":"2022-07-03T09:56:59.187322Z","shell.execute_reply.started":"2022-07-03T09:56:59.158819Z","shell.execute_reply":"2022-07-03T09:56:59.186016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"delta_bins_group","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:59.188863Z","iopub.execute_input":"2022-07-03T09:56:59.189178Z","iopub.status.idle":"2022-07-03T09:56:59.201421Z","shell.execute_reply.started":"2022-07-03T09:56:59.189148Z","shell.execute_reply":"2022-07-03T09:56:59.200165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Observations and Comments* <font>\nThe LC club has two term plans: 3 and 5 years. The delta_bins are indicating the time passed from the issue date. <br>Directly analyzing the table won't make sense, because obviously the ones where more than 5 years have passed are the borrowers who have defaulted. <br> We should rather add another level of segregation. <br> We will choose the percentage of payment received for this purpose. $\\Rightarrow$ We know that defaulters will have payment percentage below 100. So let's focus on that.","metadata":{}},{"cell_type":"markdown","source":"#### This is the list of all the borrowers who borrowed money within the past year, whose payments are not on time and have less than a 100% ","metadata":{}},{"cell_type":"code","source":"df_borrowed_within_a_yr = df[(df.Pct_Payment_Received < 100) & (df.delta_bins ==\"0-1\")]","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:59.203384Z","iopub.execute_input":"2022-07-03T09:56:59.203714Z","iopub.status.idle":"2022-07-03T09:56:59.216795Z","shell.execute_reply.started":"2022-07-03T09:56:59.203685Z","shell.execute_reply":"2022-07-03T09:56:59.215606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_borrowed_within_a_yr","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:59.218952Z","iopub.execute_input":"2022-07-03T09:56:59.219316Z","iopub.status.idle":"2022-07-03T09:56:59.258504Z","shell.execute_reply.started":"2022-07-03T09:56:59.219283Z","shell.execute_reply":"2022-07-03T09:56:59.257233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### So now let's check the loan_status of these guys","metadata":{}},{"cell_type":"code","source":"df_borrowed_within_a_yr.loan_status.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:59.25982Z","iopub.execute_input":"2022-07-03T09:56:59.260249Z","iopub.status.idle":"2022-07-03T09:56:59.272346Z","shell.execute_reply.started":"2022-07-03T09:56:59.260218Z","shell.execute_reply":"2022-07-03T09:56:59.271125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Bingo! All of them end up defaulting on their loan","metadata":{}},{"cell_type":"markdown","source":"#### So is the case for the other bins.","metadata":{}},{"cell_type":"code","source":"df[(df.Pct_Payment_Received < 100) & (df.delta_bins ==\"1-2\")][\"loan_status\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:59.273851Z","iopub.execute_input":"2022-07-03T09:56:59.274913Z","iopub.status.idle":"2022-07-03T09:56:59.290317Z","shell.execute_reply.started":"2022-07-03T09:56:59.274861Z","shell.execute_reply":"2022-07-03T09:56:59.289441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[(df.Pct_Payment_Received < 100) & (df.delta_bins ==\"2-3\")][\"loan_status\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:59.291616Z","iopub.execute_input":"2022-07-03T09:56:59.292453Z","iopub.status.idle":"2022-07-03T09:56:59.307607Z","shell.execute_reply.started":"2022-07-03T09:56:59.292418Z","shell.execute_reply":"2022-07-03T09:56:59.306015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[(df.Pct_Payment_Received < 100) & (df.delta_bins ==\"3-4\")][\"loan_status\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:59.309034Z","iopub.execute_input":"2022-07-03T09:56:59.309836Z","iopub.status.idle":"2022-07-03T09:56:59.326615Z","shell.execute_reply.started":"2022-07-03T09:56:59.309793Z","shell.execute_reply":"2022-07-03T09:56:59.3255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### In the 4-5 bin, there are still people whose loan status is current. ","metadata":{}},{"cell_type":"code","source":"df[(df.Pct_Payment_Received < 100) & (df.delta_bins ==\"4-5\")][\"loan_status\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:59.327935Z","iopub.execute_input":"2022-07-03T09:56:59.328725Z","iopub.status.idle":"2022-07-03T09:56:59.34238Z","shell.execute_reply.started":"2022-07-03T09:56:59.328688Z","shell.execute_reply":"2022-07-03T09:56:59.341124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### $\\Rightarrow$  But they are more likely to default in the future, in my opinion. It probably depends on the percentage of payment received. <br> $\\Rightarrow$ Because by this time(4-5 year from loan issue date), this percent of amount payed should be very high, close to 100%, so let's check as well","metadata":{}},{"cell_type":"code","source":"df[df.delta_bins ==\"4-5\"][\"Pct_Payment_Received\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:59.343956Z","iopub.execute_input":"2022-07-03T09:56:59.344367Z","iopub.status.idle":"2022-07-03T09:56:59.360496Z","shell.execute_reply.started":"2022-07-03T09:56:59.344334Z","shell.execute_reply":"2022-07-03T09:56:59.358609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> Let's split percent payment received in to two categories: less than 80% and greater than 80%","metadata":{}},{"cell_type":"code","source":"Pct_Payment_categories_list = [0, 80, 100]\nPct_Payment_labels_list = [\"0-80\",\">80\"]\ndf[\"Pct_Payment_bins\"] = pd.cut(df[\"Pct_Payment_Received\"], bins=Pct_Payment_categories_list,\n                              labels=Pct_Payment_labels_list)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:59.362989Z","iopub.execute_input":"2022-07-03T09:56:59.363486Z","iopub.status.idle":"2022-07-03T09:56:59.372381Z","shell.execute_reply.started":"2022-07-03T09:56:59.36344Z","shell.execute_reply":"2022-07-03T09:56:59.371159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_payment_delta_bin_group = df.groupby([\"delta_bins\", \"Pct_Payment_bins\"]).Pct_Payment_bins.count().fillna(0).unstack()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:59.373631Z","iopub.execute_input":"2022-07-03T09:56:59.374063Z","iopub.status.idle":"2022-07-03T09:56:59.38847Z","shell.execute_reply.started":"2022-07-03T09:56:59.37403Z","shell.execute_reply":"2022-07-03T09:56:59.387388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_payment_delta_bin_group","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:59.389895Z","iopub.execute_input":"2022-07-03T09:56:59.391009Z","iopub.status.idle":"2022-07-03T09:56:59.401566Z","shell.execute_reply.started":"2022-07-03T09:56:59.390974Z","shell.execute_reply":"2022-07-03T09:56:59.400441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Observations and Comments*:<font><br>\n$\\Rightarrow$ <font color=\"asparagus\">You can see that 4-5 bin has 71 borrowers who have payed less than 80% of their loan. Therefore, we can see pct_payment and delta_bin together are a great indicators of loan defaults","metadata":{}},{"cell_type":"markdown","source":"#### <font color=\"asparagus\">Since the bank only has two terms, it is best to check at the term boundaries. i.e. For the 3 year loan, check bin = 2-3 and percent_payment_bin = 0-80. ","metadata":{}},{"cell_type":"code","source":"df[(df.Pct_Payment_bins == \"0-80\") & (df.term==3) & (df.delta_bins==\"2-3\")][\"loan_status\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:59.40273Z","iopub.execute_input":"2022-07-03T09:56:59.403084Z","iopub.status.idle":"2022-07-03T09:56:59.424997Z","shell.execute_reply.started":"2022-07-03T09:56:59.403053Z","shell.execute_reply":"2022-07-03T09:56:59.423758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> As you can see all, of them default","metadata":{}},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> Similarly for the 5 year loan...","metadata":{}},{"cell_type":"code","source":"df[(df.Pct_Payment_bins == \"0-80\") & (df.term==5) & (df.delta_bins==\"4-5\")][\"loan_status\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:59.426628Z","iopub.execute_input":"2022-07-03T09:56:59.427175Z","iopub.status.idle":"2022-07-03T09:56:59.440744Z","shell.execute_reply.started":"2022-07-03T09:56:59.427137Z","shell.execute_reply":"2022-07-03T09:56:59.439011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> Most of them default too! : )","metadata":{}},{"cell_type":"code","source":"indicators.append(\"delta_bins\") # adding this to the list of indicators. delta_bins can be used along with\n#pct_payment_received to gain insight on loan defaults","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:59.442175Z","iopub.execute_input":"2022-07-03T09:56:59.442776Z","iopub.status.idle":"2022-07-03T09:56:59.447928Z","shell.execute_reply.started":"2022-07-03T09:56:59.44274Z","shell.execute_reply":"2022-07-03T09:56:59.446839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color='skyblue'>  III.2.2. In between rest of the columns(minus loan_status) <font> ","metadata":{}},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Comments:* <font>\nLet's restrict ourselvs to the columns in the indicators, to see if there are any patterns.<br>$\\Rightarrow$ grade vs int_rate<br>\n$\\Rightarrow$ purpose vs int_rate<br>\n$\\Rightarrow$ addr_state vs int_rate\n$\\Rightarrow$ fended_amnt vs int_rate    \n","metadata":{}},{"cell_type":"code","source":"indicators","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:59.449926Z","iopub.execute_input":"2022-07-03T09:56:59.450433Z","iopub.status.idle":"2022-07-03T09:56:59.462965Z","shell.execute_reply.started":"2022-07-03T09:56:59.450387Z","shell.execute_reply":"2022-07-03T09:56:59.461805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### $\\Rightarrow$ <font color='asparagus'>grade vs int_rate","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,10))\nsns.boxplot(y=\"grade\", x=\"int_rate\", data=df)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:59.464939Z","iopub.execute_input":"2022-07-03T09:56:59.465718Z","iopub.status.idle":"2022-07-03T09:56:59.789074Z","shell.execute_reply.started":"2022-07-03T09:56:59.465669Z","shell.execute_reply":"2022-07-03T09:56:59.788256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Observations and Comments:* <font>\nInterest rate is really high for Grade G borrowers. Explains why they default a lot more.<br>We already know that high interest rates attract high defaults... Wonder what the process is to decide the interest rate for a particular borrower.","metadata":{}},{"cell_type":"markdown","source":"#### $\\Rightarrow$ <font color='asparagus'>purpose vs int_rate","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,10))\nsns.boxplot(y=\"purpose\", x=\"int_rate\", data=df)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:56:59.790439Z","iopub.execute_input":"2022-07-03T09:56:59.790997Z","iopub.status.idle":"2022-07-03T09:57:00.244863Z","shell.execute_reply.started":"2022-07-03T09:56:59.790962Z","shell.execute_reply":"2022-07-03T09:57:00.243702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Observations and Comments:* <font>\nSmall businesses end up defaulting more. We can see that the interest is also on the higher side for borrowers borrowing money for the purpose of small_business ","metadata":{}},{"cell_type":"markdown","source":"#### $\\Rightarrow$ <font color='asparagus'> addr_state vs int_rate","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(30,30))\nsns.boxplot(y=\"addr_state\", x=\"int_rate\", data=df)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:57:00.246297Z","iopub.execute_input":"2022-07-03T09:57:00.246656Z","iopub.status.idle":"2022-07-03T09:57:01.524515Z","shell.execute_reply.started":"2022-07-03T09:57:00.246623Z","shell.execute_reply":"2022-07-03T09:57:01.52295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Observations and Comments:* <font>\nIt's a bit all over the place. Can't really conclude much","metadata":{}},{"cell_type":"markdown","source":"#### $\\Rightarrow$ <font color='asparagus'> funded_amnt vs int_rate","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,10))\nsns.boxplot(y=\"funded_amnt_bins\", x=\"int_rate\", data=df)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:57:01.526161Z","iopub.execute_input":"2022-07-03T09:57:01.52654Z","iopub.status.idle":"2022-07-03T09:57:01.773085Z","shell.execute_reply.started":"2022-07-03T09:57:01.526508Z","shell.execute_reply":"2022-07-03T09:57:01.771835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Observations and Comments:* <font>\nWe know from our previous analysis, higher the funded amount, higher is the interest rate and therefore the defaults. The above box plot explains the same thing.","metadata":{}},{"cell_type":"markdown","source":"#### $\\Rightarrow$ Now let's look at some other factors. When we want a loan, there are certain questions to be asked by both the LC and the borrower:\n$\\Rightarrow$ What is the loan amount? <br> \n$\\Rightarrow$ What is the rate of interest.<br> \n$\\Rightarrow$ How many years we intend to repay the loan in?","metadata":{}},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> $\\Rightarrow$ int_rate vs term <br> ","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,10))\nsns.boxplot(y=\"int_rate\", x=\"term\", data=df)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:57:01.775296Z","iopub.execute_input":"2022-07-03T09:57:01.775646Z","iopub.status.idle":"2022-07-03T09:57:01.982267Z","shell.execute_reply.started":"2022-07-03T09:57:01.775616Z","shell.execute_reply":"2022-07-03T09:57:01.981031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Observations and Comments:* <font>\nWith the above plot, we can say that for 5 year loans, the LC has decided that the rate of interest should be around 15% and for the 3 year loan, it is around 11%","metadata":{}},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> $\\Rightarrow$ int_rate vs funded_amnt <br> ","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,10))\nsns.boxplot(y=\"int_rate\", x=\"funded_amnt_bins\", data=df)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:57:01.983836Z","iopub.execute_input":"2022-07-03T09:57:01.98415Z","iopub.status.idle":"2022-07-03T09:57:02.227863Z","shell.execute_reply.started":"2022-07-03T09:57:01.984122Z","shell.execute_reply":"2022-07-03T09:57:02.226689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Observations and Comments:* <font>\nWith the above plot, we can say that higher the funded_amnt(loan_amnt), higher is the interest rate","metadata":{}},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> $\\Rightarrow$ funded_amnt vs term <br> <font>","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,10))\nsns.boxplot(y=\"funded_amnt\", x=\"term\", data=df)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:57:02.229412Z","iopub.execute_input":"2022-07-03T09:57:02.229867Z","iopub.status.idle":"2022-07-03T09:57:02.440596Z","shell.execute_reply.started":"2022-07-03T09:57:02.229834Z","shell.execute_reply":"2022-07-03T09:57:02.439448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"asparagus\"> *Observations and Comments:* <font>\nWith the above plot, we can say that larger funded amounts go with 5 year loan repayment plan. But there are so many outliers in the 3 year boxplot! Can't really say for sure : )","metadata":{}},{"cell_type":"markdown","source":"# <font color='goldenrod'> IV. Conclusion </font>","metadata":{}},{"cell_type":"code","source":"indicators","metadata":{"execution":{"iopub.status.busy":"2022-07-03T09:57:02.441802Z","iopub.execute_input":"2022-07-03T09:57:02.442101Z","iopub.status.idle":"2022-07-03T09:57:02.449816Z","shell.execute_reply.started":"2022-07-03T09:57:02.442072Z","shell.execute_reply":"2022-07-03T09:57:02.448678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color=\"asparagus\"> 1. Percent of payment received and *delta_bins*(amount of time elapsed from loan issue date to the last payment date): <font>\n\n    The LC lends money with two term plans: 3 and 5 year plans. Checking the percentage of the amount payed at the edge i.e. 2-3 or 4-5 will give us a good indication of whether the loan is going to be defaulted or not.\n    Side note: This information, however is not available at the time of loan application as earlier pointed out. But if just look at this from a data analysis point of view, it does give good insights to predicting whether a currently running loan is going to be defaulted or not.  \n<font color=\"asparagus\"> 2. Grade: <font>\n    \n    If we say grade A > B > C > D > E > F > G, then lower the loan grade, higher is the chance of defaulting.\n<font color=\"asparagus\"> 3. Annual income: <font> \n    \n    Borrowers with lower income have a higher chance of defaulting on the loan.\n<font color=\"asparagus\">4. Funded amount: <font> \n    \n    Higher the funded amount, higher is the chance of defaulting.\n<font color=\"asparagus\"> 5. Interest rate: <font>\n    \n    High interest rates attrack higher percentage of defaults.\n<font color=\"asparagus\"> 6. Inquiries in the last 6 months: <font>\n    \n    More the number of inquiries made the borrower in the last 6 months, more likely it is for the borrower to default.\n<font color=\"asparagus\"> 7. State address: <font>\n    \n    Certain states have higher chance of defaulting. Eg: Nebraska","metadata":{}},{"cell_type":"markdown","source":"# <font color='goldenrod'> V. Recommendations </font>","metadata":{}},{"cell_type":"markdown","source":"1. Lower grade loans should be avoided as they have a higher chance of defaulting. \n2. We should try to lend money to people with a higher annual income and avoid ones on the lower side like 0 - 20,000 dollars.\n3. If the loan amount asked is on the higher side, there is a higher chance of defaults. Funded amounts in the range of 0 to 15,000 dollars have around the same chances of defaults. Loan amounts greater 15,000 dollars have a higher chance of defaulting. Therefore, it's best to stay within 0 - 15,000 dollars. May within 20,000, if one is willing to take a little more risk. But safe option is within 15,000 dollars.\n4. Try to look out loans with a lower interest rate, since they are less likely to be defaulted. Interest rates within 10% are the safest options. Anything beyond 14 % should definitely be avoided, within loans > 16% having the highest chances of defaulting.\n5. Borrowers making more number of inquiries in the last 6 months are more likely to default. Borrowers who don't make any inquiries are the safes option. And borrowers making inquiries in the range 1-2 default more. Anything above that should definitely be avoided as the default rate >= 20%\n6. Borrowers from certain states tend to default more. Nebraska should definitely be avoided as 60% of the loans have been defaulted. Nevada(NV) is far second with around 21.73% chance of defaulting. So a table can be shared to lenders to make an informed decision.","metadata":{}}]}